{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run command 'conda install scikit-image' on project's v-env\n",
    "# run command 'conda install pandas' on project's v-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_TRAIN = False\n",
    "DEBUG_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_from_utf8(x):\n",
    "    return list(map(float,bin(int(x.encode().hex(),16))[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_from_bin(x):\n",
    "    res = \"\"\n",
    "    for i in x:\n",
    "        res+=str(round(i))\n",
    "        pass\n",
    "    return bytearray.fromhex(hex(int(res, 2))[2:]).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class KoreanHandwritingDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.dataset = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.dataset.iloc[idx, 0]\n",
    "        image = io.imread(img_name)\n",
    "        label = self.dataset.iloc[idx, 1]\n",
    "        label = np.array([label])\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image/255.0\n",
    "        return {'image': torch.from_numpy(image.reshape(1,64,64)),\n",
    "                'label': torch.tensor(encode_from_utf8(label[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "csv_file = \"./image-data-256/labels-map.csv\"\n",
    "root_dir = \"./image-data-256/hangul-images\"\n",
    "batch_size=64\n",
    "learning_rate=0.0002\n",
    "num_epoch=1000\n",
    "\n",
    "korean_dataset = KoreanHandwritingDataset(csv_file,root_dir, transform=transforms.Compose([ToTensor()]))\n",
    "#dataloader = DataLoader(korean_dataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "dataloader = DataLoader(korean_dataset, batch_size = batch_size, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.avgpool1 = nn.AvgPool2d(2,2) # kernel size 2x2 (32 = 64/2)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2,2) # kernel size 2x2 (32 = 64/2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(2,2) # kernel size 2x2 (16 = 32/2)\n",
    "        self.linear1 = nn.Linear(1152,378)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(378,128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(128,24)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        pass\n",
    "    def forward(self,x):\n",
    "        out = self.avgpool1(x)\n",
    "        if DEBUG_TRAIN : print('avgpool1: ', out.shape)\n",
    "        out = self.conv1(out)\n",
    "        if DEBUG_TRAIN : print('conv1: ', out.shape)\n",
    "        out = self.relu1(out)\n",
    "        if DEBUG_TRAIN : print('relu1: ', out.shape)\n",
    "        out = self.maxpool1(out)\n",
    "        if DEBUG_TRAIN : print('maxpool1: ', out.shape)\n",
    "        out = self.conv2(out)\n",
    "        if DEBUG_TRAIN : print('conv2: ', out.shape)\n",
    "        out = self.relu2(out)\n",
    "        if DEBUG_TRAIN : print('relu2: ', out.shape)\n",
    "        out = self.maxpool2(out)\n",
    "        if DEBUG_TRAIN : print('maxpool2: ', out.shape)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        if DEBUG_TRAIN : print('view: ', out.shape)\n",
    "        out = self.linear1(out)\n",
    "        if DEBUG_TRAIN : print('linear1: ', out.shape)\n",
    "        out = self.relu3(out)\n",
    "        if DEBUG_TRAIN : print('relu3: ', out.shape)\n",
    "        out = self.linear2(out)\n",
    "        if DEBUG_TRAIN : print('linear2: ', out.shape)\n",
    "        out = self.relu4(out)\n",
    "        if DEBUG_TRAIN : print('relu4: ', out.shape)\n",
    "        out = self.linear3(out)\n",
    "        if DEBUG_TRAIN : print('linear3: ', out.shape)\n",
    "        out = self.sigmoid(out)\n",
    "        if DEBUG_TRAIN : print('sigmoid: ', out.shape)\n",
    "        if DEBUG_TRAIN : print()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model=CNN().double()\n",
    "#loss_function=nn.BCEWithLogitsLoss()\n",
    "loss_function=nn.MultiLabelSoftMarginLoss()\n",
    "optimizer= torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 sequence:  0 tensor(0.7284, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  2 sequence:  0 tensor(0.6996, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  3 sequence:  0 tensor(0.6136, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  4 sequence:  0 tensor(0.5996, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  5 sequence:  0 tensor(0.5988, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  6 sequence:  0 tensor(0.5988, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  7 sequence:  0 tensor(0.5982, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  8 sequence:  0 tensor(0.5971, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  9 sequence:  0 tensor(0.5974, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  10 sequence:  0 tensor(0.5973, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  11 sequence:  0 tensor(0.5973, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  12 sequence:  0 tensor(0.5973, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  13 sequence:  0 tensor(0.5973, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  14 sequence:  0 tensor(0.5973, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  15 sequence:  0 tensor(0.5972, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  16 sequence:  0 tensor(0.5972, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  17 sequence:  0 tensor(0.5971, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  18 sequence:  0 tensor(0.5971, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  19 sequence:  0 tensor(0.5970, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  20 sequence:  0 tensor(0.5970, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  21 sequence:  0 tensor(0.5969, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  22 sequence:  0 tensor(0.5968, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  23 sequence:  0 tensor(0.5967, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  24 sequence:  0 tensor(0.5966, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  25 sequence:  0 tensor(0.5965, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  26 sequence:  0 tensor(0.5964, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  27 sequence:  0 tensor(0.5962, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  28 sequence:  0 tensor(0.5960, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  29 sequence:  0 tensor(0.5958, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  30 sequence:  0 tensor(0.5955, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  31 sequence:  0 tensor(0.5952, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  32 sequence:  0 tensor(0.5949, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  33 sequence:  0 tensor(0.5945, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  34 sequence:  0 tensor(0.5942, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  35 sequence:  0 tensor(0.5938, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  36 sequence:  0 tensor(0.5935, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  37 sequence:  0 tensor(0.5931, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  38 sequence:  0 tensor(0.5928, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  39 sequence:  0 tensor(0.5925, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  40 sequence:  0 tensor(0.5923, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  41 sequence:  0 tensor(0.5921, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  42 sequence:  0 tensor(0.5918, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  43 sequence:  0 tensor(0.5917, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  44 sequence:  0 tensor(0.5915, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  45 sequence:  0 tensor(0.5913, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  46 sequence:  0 tensor(0.5912, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  47 sequence:  0 tensor(0.5910, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  48 sequence:  0 tensor(0.5909, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  49 sequence:  0 tensor(0.5907, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  50 sequence:  0 tensor(0.5906, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  51 sequence:  0 tensor(0.5904, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  52 sequence:  0 tensor(0.5902, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  53 sequence:  0 tensor(0.5900, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  54 sequence:  0 tensor(0.5899, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  55 sequence:  0 tensor(0.5896, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  56 sequence:  0 tensor(0.5895, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  57 sequence:  0 tensor(0.5892, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  58 sequence:  0 tensor(0.5890, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  59 sequence:  0 tensor(0.5887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  60 sequence:  0 tensor(0.5886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  61 sequence:  0 tensor(0.5882, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  62 sequence:  0 tensor(0.5881, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  63 sequence:  0 tensor(0.5877, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  64 sequence:  0 tensor(0.5876, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  65 sequence:  0 tensor(0.5872, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  66 sequence:  0 tensor(0.5870, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  67 sequence:  0 tensor(0.5867, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  68 sequence:  0 tensor(0.5864, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  69 sequence:  0 tensor(0.5861, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  70 sequence:  0 tensor(0.5859, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  71 sequence:  0 tensor(0.5856, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  72 sequence:  0 tensor(0.5853, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  73 sequence:  0 tensor(0.5851, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  74 sequence:  0 tensor(0.5848, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  75 sequence:  0 tensor(0.5845, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  76 sequence:  0 tensor(0.5843, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  77 sequence:  0 tensor(0.5840, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  78 sequence:  0 tensor(0.5837, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  79 sequence:  0 tensor(0.5835, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  80 sequence:  0 tensor(0.5832, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  81 sequence:  0 tensor(0.5829, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  82 sequence:  0 tensor(0.5827, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  83 sequence:  0 tensor(0.5825, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  84 sequence:  0 tensor(0.5822, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  85 sequence:  0 tensor(0.5820, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  86 sequence:  0 tensor(0.5818, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  87 sequence:  0 tensor(0.5815, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  88 sequence:  0 tensor(0.5813, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  89 sequence:  0 tensor(0.5811, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  90 sequence:  0 tensor(0.5809, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  91 sequence:  0 tensor(0.5807, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  92 sequence:  0 tensor(0.5805, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  93 sequence:  0 tensor(0.5803, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  94 sequence:  0 tensor(0.5801, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  95 sequence:  0 tensor(0.5800, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  96 sequence:  0 tensor(0.5798, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  97 sequence:  0 tensor(0.5796, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  98 sequence:  0 tensor(0.5795, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  99 sequence:  0 tensor(0.5794, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  100 sequence:  0 tensor(0.5792, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  101 sequence:  0 tensor(0.5791, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  102 sequence:  0 tensor(0.5789, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  103 sequence:  0 tensor(0.5788, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  104 sequence:  0 tensor(0.5786, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  105 sequence:  0 tensor(0.5785, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  106 sequence:  0 tensor(0.5783, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  107 sequence:  0 tensor(0.5782, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  108 sequence:  0 tensor(0.5781, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  109 sequence:  0 tensor(0.5779, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  110 sequence:  0 tensor(0.5778, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  111 sequence:  0 tensor(0.5777, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  112 sequence:  0 tensor(0.5775, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  113 sequence:  0 tensor(0.5774, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  114 sequence:  0 tensor(0.5772, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  115 sequence:  0 tensor(0.5771, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  116 sequence:  0 tensor(0.5768, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  117 sequence:  0 tensor(0.5761, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  118 sequence:  0 tensor(0.5747, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  119 sequence:  0 tensor(0.5731, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  120 sequence:  0 tensor(0.5727, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  121 sequence:  0 tensor(0.5726, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  122 sequence:  0 tensor(0.5722, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  123 sequence:  0 tensor(0.5719, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  124 sequence:  0 tensor(0.5717, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  125 sequence:  0 tensor(0.5714, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  126 sequence:  0 tensor(0.5712, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  127 sequence:  0 tensor(0.5710, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  128 sequence:  0 tensor(0.5709, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  129 sequence:  0 tensor(0.5707, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  130 sequence:  0 tensor(0.5705, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  131 sequence:  0 tensor(0.5702, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  132 sequence:  0 tensor(0.5700, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  133 sequence:  0 tensor(0.5698, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  134 sequence:  0 tensor(0.5696, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  135 sequence:  0 tensor(0.5693, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  136 sequence:  0 tensor(0.5692, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  137 sequence:  0 tensor(0.5690, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  138 sequence:  0 tensor(0.5689, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  139 sequence:  0 tensor(0.5688, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  140 sequence:  0 tensor(0.5686, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  141 sequence:  0 tensor(0.5685, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  142 sequence:  0 tensor(0.5684, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  143 sequence:  0 tensor(0.5683, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  144 sequence:  0 tensor(0.5682, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  145 sequence:  0 tensor(0.5681, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  146 sequence:  0 tensor(0.5680, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  147 sequence:  0 tensor(0.5679, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  148 sequence:  0 tensor(0.5678, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  149 sequence:  0 tensor(0.5677, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  150 sequence:  0 tensor(0.5677, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  151 sequence:  0 tensor(0.5676, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  152 sequence:  0 tensor(0.5682, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  153 sequence:  0 tensor(0.5725, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  154 sequence:  0 tensor(0.5737, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  155 sequence:  0 tensor(0.5712, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  156 sequence:  0 tensor(0.5692, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  157 sequence:  0 tensor(0.5686, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  158 sequence:  0 tensor(0.5683, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  159 sequence:  0 tensor(0.5681, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  160 sequence:  0 tensor(0.5680, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  161 sequence:  0 tensor(0.5678, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  162 sequence:  0 tensor(0.5677, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  163 sequence:  0 tensor(0.5676, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  164 sequence:  0 tensor(0.5675, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  165 sequence:  0 tensor(0.5674, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  166 sequence:  0 tensor(0.5673, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  167 sequence:  0 tensor(0.5671, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  168 sequence:  0 tensor(0.5670, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  169 sequence:  0 tensor(0.5669, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  170 sequence:  0 tensor(0.5668, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  171 sequence:  0 tensor(0.5667, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  172 sequence:  0 tensor(0.5665, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  173 sequence:  0 tensor(0.5664, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  174 sequence:  0 tensor(0.5663, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  175 sequence:  0 tensor(0.5662, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  176 sequence:  0 tensor(0.5662, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  177 sequence:  0 tensor(0.5660, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  178 sequence:  0 tensor(0.5660, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  179 sequence:  0 tensor(0.5659, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  180 sequence:  0 tensor(0.5659, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  181 sequence:  0 tensor(0.5658, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  182 sequence:  0 tensor(0.5657, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  183 sequence:  0 tensor(0.5658, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  184 sequence:  0 tensor(0.5657, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  185 sequence:  0 tensor(0.5659, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  186 sequence:  0 tensor(0.5659, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  187 sequence:  0 tensor(0.5660, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  188 sequence:  0 tensor(0.5661, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  189 sequence:  0 tensor(0.5662, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  190 sequence:  0 tensor(0.5660, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  191 sequence:  0 tensor(0.5674, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  192 sequence:  0 tensor(0.5640, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  193 sequence:  0 tensor(0.5639, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  194 sequence:  0 tensor(0.5631, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  195 sequence:  0 tensor(0.5624, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  196 sequence:  0 tensor(0.5625, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  197 sequence:  0 tensor(0.5622, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  198 sequence:  0 tensor(0.5622, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  199 sequence:  0 tensor(0.5619, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  200 sequence:  0 tensor(0.5617, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  201 sequence:  0 tensor(0.5615, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  202 sequence:  0 tensor(0.5614, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  203 sequence:  0 tensor(0.5612, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  204 sequence:  0 tensor(0.5612, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  205 sequence:  0 tensor(0.5610, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  206 sequence:  0 tensor(0.5609, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  207 sequence:  0 tensor(0.5607, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  208 sequence:  0 tensor(0.5604, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  209 sequence:  0 tensor(0.5601, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  210 sequence:  0 tensor(0.5598, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  211 sequence:  0 tensor(0.5596, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  212 sequence:  0 tensor(0.5594, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  213 sequence:  0 tensor(0.5592, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  214 sequence:  0 tensor(0.5590, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  215 sequence:  0 tensor(0.5589, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  216 sequence:  0 tensor(0.5588, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  217 sequence:  0 tensor(0.5587, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  218 sequence:  0 tensor(0.5586, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  219 sequence:  0 tensor(0.5585, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  220 sequence:  0 tensor(0.5585, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  221 sequence:  0 tensor(0.5584, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  222 sequence:  0 tensor(0.5582, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  223 sequence:  0 tensor(0.5581, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  224 sequence:  0 tensor(0.5580, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  225 sequence:  0 tensor(0.5580, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  226 sequence:  0 tensor(0.5579, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  227 sequence:  0 tensor(0.5579, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  228 sequence:  0 tensor(0.5578, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  229 sequence:  0 tensor(0.5578, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  230 sequence:  0 tensor(0.5578, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  231 sequence:  0 tensor(0.5578, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  232 sequence:  0 tensor(0.5578, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  233 sequence:  0 tensor(0.5578, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  234 sequence:  0 tensor(0.5578, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  235 sequence:  0 tensor(0.5579, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  236 sequence:  0 tensor(0.5579, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  237 sequence:  0 tensor(0.5580, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  238 sequence:  0 tensor(0.5580, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  239 sequence:  0 tensor(0.5581, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  240 sequence:  0 tensor(0.5584, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  241 sequence:  0 tensor(0.5588, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  242 sequence:  0 tensor(0.5593, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  243 sequence:  0 tensor(0.5596, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  244 sequence:  0 tensor(0.5596, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  245 sequence:  0 tensor(0.5593, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  246 sequence:  0 tensor(0.5589, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  247 sequence:  0 tensor(0.5585, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  248 sequence:  0 tensor(0.5583, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  249 sequence:  0 tensor(0.5582, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  250 sequence:  0 tensor(0.5582, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  251 sequence:  0 tensor(0.5581, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  252 sequence:  0 tensor(0.5581, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  253 sequence:  0 tensor(0.5580, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  254 sequence:  0 tensor(0.5579, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  255 sequence:  0 tensor(0.5579, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  256 sequence:  0 tensor(0.5577, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  257 sequence:  0 tensor(0.5576, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  258 sequence:  0 tensor(0.5576, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  259 sequence:  0 tensor(0.5575, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  260 sequence:  0 tensor(0.5577, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  261 sequence:  0 tensor(0.5582, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  262 sequence:  0 tensor(0.5583, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  263 sequence:  0 tensor(0.5578, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  264 sequence:  0 tensor(0.5572, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  265 sequence:  0 tensor(0.5569, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  266 sequence:  0 tensor(0.5567, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  267 sequence:  0 tensor(0.5567, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  268 sequence:  0 tensor(0.5566, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  269 sequence:  0 tensor(0.5565, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  270 sequence:  0 tensor(0.5565, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  271 sequence:  0 tensor(0.5565, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  272 sequence:  0 tensor(0.5565, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  273 sequence:  0 tensor(0.5565, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  274 sequence:  0 tensor(0.5564, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  275 sequence:  0 tensor(0.5564, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  276 sequence:  0 tensor(0.5563, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  277 sequence:  0 tensor(0.5563, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  278 sequence:  0 tensor(0.5562, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  279 sequence:  0 tensor(0.5561, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  280 sequence:  0 tensor(0.5560, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  281 sequence:  0 tensor(0.5559, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  282 sequence:  0 tensor(0.5558, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  283 sequence:  0 tensor(0.5558, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  284 sequence:  0 tensor(0.5558, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  285 sequence:  0 tensor(0.5558, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  286 sequence:  0 tensor(0.5559, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  287 sequence:  0 tensor(0.5561, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  288 sequence:  0 tensor(0.5563, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  289 sequence:  0 tensor(0.5565, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  290 sequence:  0 tensor(0.5570, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  291 sequence:  0 tensor(0.5577, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  292 sequence:  0 tensor(0.5577, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  293 sequence:  0 tensor(0.5571, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  294 sequence:  0 tensor(0.5568, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  295 sequence:  0 tensor(0.5566, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  296 sequence:  0 tensor(0.5562, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  297 sequence:  0 tensor(0.5559, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  298 sequence:  0 tensor(0.5557, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  299 sequence:  0 tensor(0.5556, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  300 sequence:  0 tensor(0.5555, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  301 sequence:  0 tensor(0.5555, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  302 sequence:  0 tensor(0.5555, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  303 sequence:  0 tensor(0.5555, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  304 sequence:  0 tensor(0.5554, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  305 sequence:  0 tensor(0.5553, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  306 sequence:  0 tensor(0.5551, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  307 sequence:  0 tensor(0.5551, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  308 sequence:  0 tensor(0.5552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  309 sequence:  0 tensor(0.5552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  310 sequence:  0 tensor(0.5551, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  311 sequence:  0 tensor(0.5550, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  312 sequence:  0 tensor(0.5548, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  313 sequence:  0 tensor(0.5542, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  314 sequence:  0 tensor(0.5539, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  315 sequence:  0 tensor(0.5540, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  316 sequence:  0 tensor(0.5546, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  317 sequence:  0 tensor(0.5554, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  318 sequence:  0 tensor(0.5561, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  319 sequence:  0 tensor(0.5561, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  320 sequence:  0 tensor(0.5557, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  321 sequence:  0 tensor(0.5552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  322 sequence:  0 tensor(0.5552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  323 sequence:  0 tensor(0.5554, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  324 sequence:  0 tensor(0.5548, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  325 sequence:  0 tensor(0.5541, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  326 sequence:  0 tensor(0.5538, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  327 sequence:  0 tensor(0.5539, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  328 sequence:  0 tensor(0.5540, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  329 sequence:  0 tensor(0.5541, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  330 sequence:  0 tensor(0.5542, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  331 sequence:  0 tensor(0.5542, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  332 sequence:  0 tensor(0.5540, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  333 sequence:  0 tensor(0.5538, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  334 sequence:  0 tensor(0.5536, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  335 sequence:  0 tensor(0.5539, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  336 sequence:  0 tensor(0.5549, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  337 sequence:  0 tensor(0.5561, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  338 sequence:  0 tensor(0.5563, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  339 sequence:  0 tensor(0.5554, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  340 sequence:  0 tensor(0.5545, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  341 sequence:  0 tensor(0.5541, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  342 sequence:  0 tensor(0.5540, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  343 sequence:  0 tensor(0.5537, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  344 sequence:  0 tensor(0.5535, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  345 sequence:  0 tensor(0.5534, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  346 sequence:  0 tensor(0.5532, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  347 sequence:  0 tensor(0.5532, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  348 sequence:  0 tensor(0.5534, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  349 sequence:  0 tensor(0.5533, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  350 sequence:  0 tensor(0.5533, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  351 sequence:  0 tensor(0.5533, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  352 sequence:  0 tensor(0.5535, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  353 sequence:  0 tensor(0.5536, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  354 sequence:  0 tensor(0.5534, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  355 sequence:  0 tensor(0.5527, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  356 sequence:  0 tensor(0.5524, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  357 sequence:  0 tensor(0.5525, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  358 sequence:  0 tensor(0.5528, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  359 sequence:  0 tensor(0.5532, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  360 sequence:  0 tensor(0.5537, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  361 sequence:  0 tensor(0.5544, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  362 sequence:  0 tensor(0.5549, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  363 sequence:  0 tensor(0.5552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  364 sequence:  0 tensor(0.5545, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  365 sequence:  0 tensor(0.5535, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  366 sequence:  0 tensor(0.5530, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  367 sequence:  0 tensor(0.5525, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  368 sequence:  0 tensor(0.5522, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  369 sequence:  0 tensor(0.5523, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  370 sequence:  0 tensor(0.5526, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  371 sequence:  0 tensor(0.5526, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  372 sequence:  0 tensor(0.5525, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  373 sequence:  0 tensor(0.5525, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  374 sequence:  0 tensor(0.5527, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  375 sequence:  0 tensor(0.5526, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  376 sequence:  0 tensor(0.5525, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  377 sequence:  0 tensor(0.5525, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  378 sequence:  0 tensor(0.5529, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  379 sequence:  0 tensor(0.5534, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  380 sequence:  0 tensor(0.5537, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  381 sequence:  0 tensor(0.5535, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  382 sequence:  0 tensor(0.5529, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  383 sequence:  0 tensor(0.5522, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  384 sequence:  0 tensor(0.5516, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  385 sequence:  0 tensor(0.5516, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  386 sequence:  0 tensor(0.5519, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  387 sequence:  0 tensor(0.5519, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  388 sequence:  0 tensor(0.5517, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  389 sequence:  0 tensor(0.5515, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  390 sequence:  0 tensor(0.5515, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  391 sequence:  0 tensor(0.5516, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  392 sequence:  0 tensor(0.5516, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  393 sequence:  0 tensor(0.5518, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  394 sequence:  0 tensor(0.5521, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  395 sequence:  0 tensor(0.5524, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  396 sequence:  0 tensor(0.5523, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  397 sequence:  0 tensor(0.5519, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  398 sequence:  0 tensor(0.5514, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  399 sequence:  0 tensor(0.5511, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  400 sequence:  0 tensor(0.5509, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  401 sequence:  0 tensor(0.5508, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  402 sequence:  0 tensor(0.5510, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  403 sequence:  0 tensor(0.5513, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  404 sequence:  0 tensor(0.5516, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  405 sequence:  0 tensor(0.5518, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  406 sequence:  0 tensor(0.5518, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  407 sequence:  0 tensor(0.5518, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  408 sequence:  0 tensor(0.5518, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  409 sequence:  0 tensor(0.5523, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  410 sequence:  0 tensor(0.5529, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  411 sequence:  0 tensor(0.5530, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  412 sequence:  0 tensor(0.5523, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  413 sequence:  0 tensor(0.5512, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  414 sequence:  0 tensor(0.5505, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  415 sequence:  0 tensor(0.5504, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  416 sequence:  0 tensor(0.5507, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  417 sequence:  0 tensor(0.5510, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  418 sequence:  0 tensor(0.5513, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  419 sequence:  0 tensor(0.5514, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  420 sequence:  0 tensor(0.5510, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  421 sequence:  0 tensor(0.5504, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  422 sequence:  0 tensor(0.5520, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  423 sequence:  0 tensor(0.5542, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  424 sequence:  0 tensor(0.5539, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  425 sequence:  0 tensor(0.5513, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  426 sequence:  0 tensor(0.5504, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  427 sequence:  0 tensor(0.5502, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  428 sequence:  0 tensor(0.5500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  429 sequence:  0 tensor(0.5500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  430 sequence:  0 tensor(0.5503, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  431 sequence:  0 tensor(0.5510, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  432 sequence:  0 tensor(0.5520, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  433 sequence:  0 tensor(0.5524, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  434 sequence:  0 tensor(0.5517, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  435 sequence:  0 tensor(0.5503, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  436 sequence:  0 tensor(0.5497, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  437 sequence:  0 tensor(0.5496, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  438 sequence:  0 tensor(0.5497, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  439 sequence:  0 tensor(0.5498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  440 sequence:  0 tensor(0.5498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  441 sequence:  0 tensor(0.5498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  442 sequence:  0 tensor(0.5498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  443 sequence:  0 tensor(0.5498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  444 sequence:  0 tensor(0.5496, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  445 sequence:  0 tensor(0.5494, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  446 sequence:  0 tensor(0.5491, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  447 sequence:  0 tensor(0.5490, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  448 sequence:  0 tensor(0.5491, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  449 sequence:  0 tensor(0.5494, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  450 sequence:  0 tensor(0.5498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  451 sequence:  0 tensor(0.5502, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  452 sequence:  0 tensor(0.5502, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  453 sequence:  0 tensor(0.5497, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  454 sequence:  0 tensor(0.5492, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  455 sequence:  0 tensor(0.5486, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  456 sequence:  0 tensor(0.5485, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  457 sequence:  0 tensor(0.5487, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  458 sequence:  0 tensor(0.5492, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  459 sequence:  0 tensor(0.5497, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  460 sequence:  0 tensor(0.5498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  461 sequence:  0 tensor(0.5492, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  462 sequence:  0 tensor(0.5486, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  463 sequence:  0 tensor(0.5486, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  464 sequence:  0 tensor(0.5491, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  465 sequence:  0 tensor(0.5495, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  466 sequence:  0 tensor(0.5494, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  467 sequence:  0 tensor(0.5486, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  468 sequence:  0 tensor(0.5481, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  469 sequence:  0 tensor(0.5479, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  470 sequence:  0 tensor(0.5478, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  471 sequence:  0 tensor(0.5478, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  472 sequence:  0 tensor(0.5479, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  473 sequence:  0 tensor(0.5478, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  474 sequence:  0 tensor(0.5477, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  475 sequence:  0 tensor(0.5475, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  476 sequence:  0 tensor(0.5474, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  477 sequence:  0 tensor(0.5477, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  478 sequence:  0 tensor(0.5482, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  479 sequence:  0 tensor(0.5484, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  480 sequence:  0 tensor(0.5485, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  481 sequence:  0 tensor(0.5483, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  482 sequence:  0 tensor(0.5478, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  483 sequence:  0 tensor(0.5475, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  484 sequence:  0 tensor(0.5474, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  485 sequence:  0 tensor(0.5476, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  486 sequence:  0 tensor(0.5480, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  487 sequence:  0 tensor(0.5481, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  488 sequence:  0 tensor(0.5477, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  489 sequence:  0 tensor(0.5471, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  490 sequence:  0 tensor(0.5468, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  491 sequence:  0 tensor(0.5470, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  492 sequence:  0 tensor(0.5473, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  493 sequence:  0 tensor(0.5474, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  494 sequence:  0 tensor(0.5474, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  495 sequence:  0 tensor(0.5472, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  496 sequence:  0 tensor(0.5474, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  497 sequence:  0 tensor(0.5475, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  498 sequence:  0 tensor(0.5474, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  499 sequence:  0 tensor(0.5474, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  500 sequence:  0 tensor(0.5476, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  501 sequence:  0 tensor(0.5477, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  502 sequence:  0 tensor(0.5470, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  503 sequence:  0 tensor(0.5466, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  504 sequence:  0 tensor(0.5467, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  505 sequence:  0 tensor(0.5467, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  506 sequence:  0 tensor(0.5466, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  507 sequence:  0 tensor(0.5466, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  508 sequence:  0 tensor(0.5467, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  509 sequence:  0 tensor(0.5470, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  510 sequence:  0 tensor(0.5475, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  511 sequence:  0 tensor(0.5482, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  512 sequence:  0 tensor(0.5487, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  513 sequence:  0 tensor(0.5484, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  514 sequence:  0 tensor(0.5477, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  515 sequence:  0 tensor(0.5494, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  516 sequence:  0 tensor(0.5490, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  517 sequence:  0 tensor(0.5482, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  518 sequence:  0 tensor(0.5467, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  519 sequence:  0 tensor(0.5463, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  520 sequence:  0 tensor(0.5472, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  521 sequence:  0 tensor(0.5482, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  522 sequence:  0 tensor(0.5482, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  523 sequence:  0 tensor(0.5475, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  524 sequence:  0 tensor(0.5475, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  525 sequence:  0 tensor(0.5466, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  526 sequence:  0 tensor(0.5461, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  527 sequence:  0 tensor(0.5460, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  528 sequence:  0 tensor(0.5462, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  529 sequence:  0 tensor(0.5466, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  530 sequence:  0 tensor(0.5466, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  531 sequence:  0 tensor(0.5455, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  532 sequence:  0 tensor(0.5452, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  533 sequence:  0 tensor(0.5452, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  534 sequence:  0 tensor(0.5451, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  535 sequence:  0 tensor(0.5450, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  536 sequence:  0 tensor(0.5450, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  537 sequence:  0 tensor(0.5449, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  538 sequence:  0 tensor(0.5448, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  539 sequence:  0 tensor(0.5447, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  540 sequence:  0 tensor(0.5446, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  541 sequence:  0 tensor(0.5446, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  542 sequence:  0 tensor(0.5446, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  543 sequence:  0 tensor(0.5445, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  544 sequence:  0 tensor(0.5445, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  545 sequence:  0 tensor(0.5444, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  546 sequence:  0 tensor(0.5444, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  547 sequence:  0 tensor(0.5444, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  548 sequence:  0 tensor(0.5444, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  549 sequence:  0 tensor(0.5444, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  550 sequence:  0 tensor(0.5443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  551 sequence:  0 tensor(0.5443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  552 sequence:  0 tensor(0.5443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  553 sequence:  0 tensor(0.5443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  554 sequence:  0 tensor(0.5443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  555 sequence:  0 tensor(0.5442, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  556 sequence:  0 tensor(0.5442, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  557 sequence:  0 tensor(0.5442, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  558 sequence:  0 tensor(0.5441, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  559 sequence:  0 tensor(0.5441, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  560 sequence:  0 tensor(0.5441, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  561 sequence:  0 tensor(0.5440, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  562 sequence:  0 tensor(0.5440, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  563 sequence:  0 tensor(0.5439, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  564 sequence:  0 tensor(0.5439, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  565 sequence:  0 tensor(0.5439, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  566 sequence:  0 tensor(0.5438, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  567 sequence:  0 tensor(0.5438, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  568 sequence:  0 tensor(0.5437, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  569 sequence:  0 tensor(0.5436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  570 sequence:  0 tensor(0.5436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  571 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  572 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  573 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  574 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  575 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  576 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  577 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  578 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  579 sequence:  0 tensor(0.5436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  580 sequence:  0 tensor(0.5436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  581 sequence:  0 tensor(0.5435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  582 sequence:  0 tensor(0.5436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  583 sequence:  0 tensor(0.5436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  584 sequence:  0 tensor(0.5441, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  585 sequence:  0 tensor(0.5443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  586 sequence:  0 tensor(0.5442, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  587 sequence:  0 tensor(0.5443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  588 sequence:  0 tensor(0.5438, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  589 sequence:  0 tensor(0.5436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  590 sequence:  0 tensor(0.5449, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  591 sequence:  0 tensor(0.5456, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  592 sequence:  0 tensor(0.5465, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  593 sequence:  0 tensor(0.5453, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  594 sequence:  0 tensor(0.5446, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  595 sequence:  0 tensor(0.5453, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  596 sequence:  0 tensor(0.5457, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  597 sequence:  0 tensor(0.5458, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  598 sequence:  0 tensor(0.5456, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  599 sequence:  0 tensor(0.5457, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  600 sequence:  0 tensor(0.5470, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  601 sequence:  0 tensor(0.5458, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  602 sequence:  0 tensor(0.5443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  603 sequence:  0 tensor(0.5452, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  604 sequence:  0 tensor(0.5460, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  605 sequence:  0 tensor(0.5428, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  606 sequence:  0 tensor(0.5423, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  607 sequence:  0 tensor(0.5423, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  608 sequence:  0 tensor(0.5419, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  609 sequence:  0 tensor(0.5419, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  610 sequence:  0 tensor(0.5418, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  611 sequence:  0 tensor(0.5417, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  612 sequence:  0 tensor(0.5417, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  613 sequence:  0 tensor(0.5416, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  614 sequence:  0 tensor(0.5415, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  615 sequence:  0 tensor(0.5414, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  616 sequence:  0 tensor(0.5413, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  617 sequence:  0 tensor(0.5412, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  618 sequence:  0 tensor(0.5411, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  619 sequence:  0 tensor(0.5410, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  620 sequence:  0 tensor(0.5409, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  621 sequence:  0 tensor(0.5408, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  622 sequence:  0 tensor(0.5408, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  623 sequence:  0 tensor(0.5406, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  624 sequence:  0 tensor(0.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  625 sequence:  0 tensor(0.5408, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  626 sequence:  0 tensor(0.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  627 sequence:  0 tensor(0.5406, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  628 sequence:  0 tensor(0.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  629 sequence:  0 tensor(0.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  630 sequence:  0 tensor(0.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  631 sequence:  0 tensor(0.5405, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  632 sequence:  0 tensor(0.5405, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  633 sequence:  0 tensor(0.5408, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  634 sequence:  0 tensor(0.5408, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  635 sequence:  0 tensor(0.5406, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  636 sequence:  0 tensor(0.5410, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  637 sequence:  0 tensor(0.5405, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  638 sequence:  0 tensor(0.5411, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  639 sequence:  0 tensor(0.5408, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  640 sequence:  0 tensor(0.5406, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  641 sequence:  0 tensor(0.5411, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  642 sequence:  0 tensor(0.5410, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  643 sequence:  0 tensor(0.5413, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  644 sequence:  0 tensor(0.5415, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  645 sequence:  0 tensor(0.5415, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  646 sequence:  0 tensor(0.5417, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  647 sequence:  0 tensor(0.5413, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  648 sequence:  0 tensor(0.5412, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  649 sequence:  0 tensor(0.5424, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  650 sequence:  0 tensor(0.5425, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  651 sequence:  0 tensor(0.5466, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  652 sequence:  0 tensor(0.5452, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  653 sequence:  0 tensor(0.5431, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  654 sequence:  0 tensor(0.5439, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  655 sequence:  0 tensor(0.5479, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  656 sequence:  0 tensor(0.5467, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  657 sequence:  0 tensor(0.5417, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  658 sequence:  0 tensor(0.5413, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  659 sequence:  0 tensor(0.5415, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  660 sequence:  0 tensor(0.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  661 sequence:  0 tensor(0.5412, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  662 sequence:  0 tensor(0.5415, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  663 sequence:  0 tensor(0.5404, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  664 sequence:  0 tensor(0.5403, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  665 sequence:  0 tensor(0.5405, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  666 sequence:  0 tensor(0.5406, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  667 sequence:  0 tensor(0.5404, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  668 sequence:  0 tensor(0.5403, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  669 sequence:  0 tensor(0.5402, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  670 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  671 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  672 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  673 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  674 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  675 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  676 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  677 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  678 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  679 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  680 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  681 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  682 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  683 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  684 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  685 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  686 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  687 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  688 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  689 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  690 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  691 sequence:  0 tensor(0.5402, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  692 sequence:  0 tensor(0.5402, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  693 sequence:  0 tensor(0.5403, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  694 sequence:  0 tensor(0.5403, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  695 sequence:  0 tensor(0.5402, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  696 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  697 sequence:  0 tensor(0.5399, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  698 sequence:  0 tensor(0.5403, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  699 sequence:  0 tensor(0.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  700 sequence:  0 tensor(0.5400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  701 sequence:  0 tensor(0.5399, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  702 sequence:  0 tensor(0.5399, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  703 sequence:  0 tensor(0.5405, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  704 sequence:  0 tensor(0.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  705 sequence:  0 tensor(0.5414, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  706 sequence:  0 tensor(0.5421, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  707 sequence:  0 tensor(0.5421, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  708 sequence:  0 tensor(0.5437, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  709 sequence:  0 tensor(0.5416, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  710 sequence:  0 tensor(0.5417, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  711 sequence:  0 tensor(0.5455, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  712 sequence:  0 tensor(0.5437, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  713 sequence:  0 tensor(0.5419, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  714 sequence:  0 tensor(0.5406, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  715 sequence:  0 tensor(0.5437, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  716 sequence:  0 tensor(0.5450, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  717 sequence:  0 tensor(0.5401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  718 sequence:  0 tensor(0.5390, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  719 sequence:  0 tensor(0.5385, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  720 sequence:  0 tensor(0.5383, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  721 sequence:  0 tensor(0.5380, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  722 sequence:  0 tensor(0.5379, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  723 sequence:  0 tensor(0.5379, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  724 sequence:  0 tensor(0.5378, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  725 sequence:  0 tensor(0.5377, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  726 sequence:  0 tensor(0.5377, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  727 sequence:  0 tensor(0.5376, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  728 sequence:  0 tensor(0.5376, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  729 sequence:  0 tensor(0.5377, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  730 sequence:  0 tensor(0.5376, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  731 sequence:  0 tensor(0.5375, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  732 sequence:  0 tensor(0.5375, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  733 sequence:  0 tensor(0.5375, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  734 sequence:  0 tensor(0.5374, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  735 sequence:  0 tensor(0.5374, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  736 sequence:  0 tensor(0.5374, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  737 sequence:  0 tensor(0.5373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  738 sequence:  0 tensor(0.5373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  739 sequence:  0 tensor(0.5373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  740 sequence:  0 tensor(0.5373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  741 sequence:  0 tensor(0.5371, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  742 sequence:  0 tensor(0.5372, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  743 sequence:  0 tensor(0.5368, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  744 sequence:  0 tensor(0.5366, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  745 sequence:  0 tensor(0.5364, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  746 sequence:  0 tensor(0.5365, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  747 sequence:  0 tensor(0.5363, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  748 sequence:  0 tensor(0.5360, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  749 sequence:  0 tensor(0.5371, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  750 sequence:  0 tensor(0.5373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  751 sequence:  0 tensor(0.5372, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  752 sequence:  0 tensor(0.5373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  753 sequence:  0 tensor(0.5371, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  754 sequence:  0 tensor(0.5363, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  755 sequence:  0 tensor(0.5357, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  756 sequence:  0 tensor(0.5358, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  757 sequence:  0 tensor(0.5361, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  758 sequence:  0 tensor(0.5360, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  759 sequence:  0 tensor(0.5367, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  760 sequence:  0 tensor(0.5355, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  761 sequence:  0 tensor(0.5363, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  762 sequence:  0 tensor(0.5361, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  763 sequence:  0 tensor(0.5350, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  764 sequence:  0 tensor(0.5353, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  765 sequence:  0 tensor(0.5366, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  766 sequence:  0 tensor(0.5373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  767 sequence:  0 tensor(0.5368, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  768 sequence:  0 tensor(0.5355, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  769 sequence:  0 tensor(0.5361, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  770 sequence:  0 tensor(0.5352, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  771 sequence:  0 tensor(0.5353, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  772 sequence:  0 tensor(0.5357, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  773 sequence:  0 tensor(0.5351, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  774 sequence:  0 tensor(0.5346, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  775 sequence:  0 tensor(0.5348, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  776 sequence:  0 tensor(0.5352, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  777 sequence:  0 tensor(0.5392, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  778 sequence:  0 tensor(0.5392, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  779 sequence:  0 tensor(0.5367, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  780 sequence:  0 tensor(0.5347, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  781 sequence:  0 tensor(0.5354, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  782 sequence:  0 tensor(0.5353, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  783 sequence:  0 tensor(0.5343, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  784 sequence:  0 tensor(0.5342, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  785 sequence:  0 tensor(0.5341, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  786 sequence:  0 tensor(0.5343, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  787 sequence:  0 tensor(0.5344, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  788 sequence:  0 tensor(0.5342, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  789 sequence:  0 tensor(0.5340, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  790 sequence:  0 tensor(0.5339, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  791 sequence:  0 tensor(0.5341, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  792 sequence:  0 tensor(0.5383, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  793 sequence:  0 tensor(0.5340, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  794 sequence:  0 tensor(0.5337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  795 sequence:  0 tensor(0.5345, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  796 sequence:  0 tensor(0.5341, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  797 sequence:  0 tensor(0.5345, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  798 sequence:  0 tensor(0.5337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  799 sequence:  0 tensor(0.5337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  800 sequence:  0 tensor(0.5337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  801 sequence:  0 tensor(0.5336, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  802 sequence:  0 tensor(0.5336, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  803 sequence:  0 tensor(0.5335, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  804 sequence:  0 tensor(0.5335, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  805 sequence:  0 tensor(0.5334, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  806 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  807 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  808 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  809 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  810 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  811 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  812 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  813 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  814 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  815 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  816 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  817 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  818 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  819 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  820 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  821 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  822 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  823 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  824 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  825 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  826 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  827 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  828 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  829 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  830 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  831 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  832 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  833 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  834 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  835 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  836 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  837 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  838 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  839 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  840 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  841 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  842 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  843 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  844 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  845 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  846 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  847 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  848 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  849 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  850 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  851 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  852 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  853 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  854 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  855 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  856 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  857 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  858 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  859 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  860 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  861 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  862 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  863 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  864 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  865 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  866 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  867 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  868 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  869 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  870 sequence:  0 tensor(0.5334, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  871 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  872 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  873 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  874 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  875 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  876 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  877 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  878 sequence:  0 tensor(0.5334, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  879 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  880 sequence:  0 tensor(0.5339, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  881 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  882 sequence:  0 tensor(0.5336, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  883 sequence:  0 tensor(0.5334, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  884 sequence:  0 tensor(0.5343, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  885 sequence:  0 tensor(0.5336, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  886 sequence:  0 tensor(0.5337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  887 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  888 sequence:  0 tensor(0.5335, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  889 sequence:  0 tensor(0.5340, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  890 sequence:  0 tensor(0.5342, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  891 sequence:  0 tensor(0.5346, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  892 sequence:  0 tensor(0.5372, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  893 sequence:  0 tensor(0.5398, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  894 sequence:  0 tensor(0.5423, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  895 sequence:  0 tensor(0.5398, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  896 sequence:  0 tensor(0.5383, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  897 sequence:  0 tensor(0.5357, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  898 sequence:  0 tensor(0.5344, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  899 sequence:  0 tensor(0.5386, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  900 sequence:  0 tensor(0.5337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  901 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  902 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  903 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  904 sequence:  0 tensor(0.5336, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  905 sequence:  0 tensor(0.5338, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  906 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  907 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  908 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  909 sequence:  0 tensor(0.5348, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  910 sequence:  0 tensor(0.5336, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  911 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  912 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  913 sequence:  0 tensor(0.5337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  914 sequence:  0 tensor(0.5336, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  915 sequence:  0 tensor(0.5337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  916 sequence:  0 tensor(0.5339, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  917 sequence:  0 tensor(0.5335, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  918 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  919 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  920 sequence:  0 tensor(0.5341, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  921 sequence:  0 tensor(0.5349, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  922 sequence:  0 tensor(0.5348, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  923 sequence:  0 tensor(0.5329, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  924 sequence:  0 tensor(0.5341, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  925 sequence:  0 tensor(0.5339, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  926 sequence:  0 tensor(0.5332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  927 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  928 sequence:  0 tensor(0.5329, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  929 sequence:  0 tensor(0.5334, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  930 sequence:  0 tensor(0.5329, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  931 sequence:  0 tensor(0.5329, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  932 sequence:  0 tensor(0.5331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  933 sequence:  0 tensor(0.5328, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  934 sequence:  0 tensor(0.5328, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  935 sequence:  0 tensor(0.5328, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  936 sequence:  0 tensor(0.5326, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  937 sequence:  0 tensor(0.5325, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  938 sequence:  0 tensor(0.5325, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  939 sequence:  0 tensor(0.5322, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  940 sequence:  0 tensor(0.5322, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  941 sequence:  0 tensor(0.5322, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  942 sequence:  0 tensor(0.5322, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  943 sequence:  0 tensor(0.5321, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  944 sequence:  0 tensor(0.5320, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  945 sequence:  0 tensor(0.5320, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  946 sequence:  0 tensor(0.5322, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  947 sequence:  0 tensor(0.5323, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  948 sequence:  0 tensor(0.5318, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  949 sequence:  0 tensor(0.5317, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  950 sequence:  0 tensor(0.5321, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  951 sequence:  0 tensor(0.5342, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  952 sequence:  0 tensor(0.5360, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  953 sequence:  0 tensor(0.5325, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  954 sequence:  0 tensor(0.5326, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  955 sequence:  0 tensor(0.5322, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  956 sequence:  0 tensor(0.5324, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  957 sequence:  0 tensor(0.5317, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  958 sequence:  0 tensor(0.5333, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  959 sequence:  0 tensor(0.5317, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  960 sequence:  0 tensor(0.5320, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  961 sequence:  0 tensor(0.5317, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  962 sequence:  0 tensor(0.5316, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  963 sequence:  0 tensor(0.5315, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  964 sequence:  0 tensor(0.5316, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  965 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  966 sequence:  0 tensor(0.5315, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  967 sequence:  0 tensor(0.5316, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  968 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  969 sequence:  0 tensor(0.5315, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  970 sequence:  0 tensor(0.5315, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  971 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  972 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  973 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  974 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  975 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  976 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  977 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  978 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  979 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  980 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  981 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  982 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  983 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  984 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  985 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  986 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  987 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  988 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  989 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  990 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  991 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  992 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  993 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  994 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  995 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  996 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  997 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  998 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  999 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "epoch:  1000 sequence:  0 tensor(0.5314, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_arr=[]\n",
    "for i in range(num_epoch):\n",
    "    for j, sample in enumerate(dataloader):\n",
    "        x = sample['image']\n",
    "        y = sample['label']\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(x)\n",
    "        loss=loss_function(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j == 0:\n",
    "            if DEBUG_DATA:\n",
    "                plt.figure(figsize=(32, 32))\n",
    "                for k, img in enumerate(x):\n",
    "                    plt.subplot(8, 8, k+1)\n",
    "                    plt.imshow(img.squeeze())\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "                    pass\n",
    "                plt.show()\n",
    "            print('epoch: ', i+1, 'sequence: ', j, loss)\n",
    "            loss_arr.append(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./saved_model/MultiLabelSoftMarginLoss-1000epoch.torchModel\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear1): Linear(in_features=1152, out_features=378, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (linear2): Linear(in_features=378, out_features=128, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (linear3): Linear(in_features=128, out_features=24, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = CNN().double()\n",
    "loaded_model.load_state_dict(torch.load(PATH))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 값:  끤 , 실제 값:  다\n",
      "출력 값:  끤 , 실제 값:  다\n",
      "출력 값:  끤 , 실제 값:  다\n",
      "출력 값:  푐 , 실제 값:  하\n",
      "출력 값:  푐 , 실제 값:  하\n",
      "출력 값:  푐 , 실제 값:  하\n",
      "출력 값:  푐 , 실제 값:  하\n",
      "출력 값:  죀 , 실제 값:  지\n",
      "출력 값:  죀 , 실제 값:  지\n",
      "출력 값:  죀 , 실제 값:  지\n",
      "출력 값:  죀 , 실제 값:  지\n",
      "출력 값:  왴 , 실제 값:  이\n",
      "출력 값:  왴 , 실제 값:  이\n",
      "출력 값:  왴 , 실제 값:  이\n",
      "출력 값:  왴 , 실제 값:  이\n",
      "출력 값:  갰 , 실제 값:  기\n",
      "출력 값:  갰 , 실제 값:  기\n",
      "출력 값:  갰 , 실제 값:  기\n",
      "출력 값:  갰 , 실제 값:  기\n",
      "출력 값:  렬 , 실제 값:  리\n",
      "출력 값:  렬 , 실제 값:  리\n",
      "출력 값:  렬 , 실제 값:  리\n",
      "출력 값:  렬 , 실제 값:  리\n",
      "출력 값:  가 , 실제 값:  가\n",
      "출력 값:  가 , 실제 값:  가\n",
      "출력 값:  가 , 실제 값:  가\n",
      "출력 값:  가 , 실제 값:  가\n",
      "출력 값:  삌 , 실제 값:  사\n",
      "출력 값:  삌 , 실제 값:  사\n",
      "출력 값:  삌 , 실제 값:  사\n",
      "출력 값:  삌 , 실제 값:  사\n",
      "출력 값:  쒀 , 실제 값:  자\n",
      "출력 값:  쒐 , 실제 값:  자\n",
      "출력 값:  쒐 , 실제 값:  자\n",
      "출력 값:  쒀 , 실제 값:  자\n",
      "출력 값:  뀀 , 실제 값:  대\n",
      "출력 값:  뀀 , 실제 값:  대\n",
      "출력 값:  뀀 , 실제 값:  대\n",
      "출력 값:  뀀 , 실제 값:  대\n",
      "출력 값:  저 , 실제 값:  적\n",
      "출력 값:  저 , 실제 값:  적\n",
      "출력 값:  저 , 실제 값:  적\n",
      "출력 값:  ꠀ , 실제 값:  적\n",
      "출력 값:  쐴 , 실제 값:  어\n",
      "출력 값:  쐴 , 실제 값:  어\n",
      "출력 값:  쐴 , 실제 값:  어\n",
      "출력 값:  쐴 , 실제 값:  어\n",
      "출력 값:  쑄 , 실제 값:  아\n",
      "출력 값:  쑄 , 실제 값:  아\n",
      "출력 값:  쑄 , 실제 값:  아\n",
      "출력 값:  쑄 , 실제 값:  아\n",
      "출력 값:  싌 , 실제 값:  시\n",
      "출력 값:  싌 , 실제 값:  시\n",
      "출력 값:  싌 , 실제 값:  시\n",
      "출력 값:  싌 , 실제 값:  시\n",
      "출력 값:  쒀 , 실제 값:  장\n",
      "출력 값:  쒀 , 실제 값:  장\n",
      "출력 값:  쒀 , 실제 값:  장\n",
      "출력 값:  쒀 , 실제 값:  장\n",
      "출력 값:  수 , 실제 값:  수\n",
      "출력 값:  수 , 실제 값:  수\n",
      "출력 값:  쀘 , 실제 값:  수\n",
      "출력 값:  수 , 실제 값:  수\n",
      "출력 값:  되 , 실제 값:  되\n",
      "출력 값:  뀘 , 실제 값:  되\n",
      "출력 값:  되 , 실제 값:  되\n",
      "출력 값:  뀘 , 실제 값:  되\n",
      "출력 값:  저 , 실제 값:  전\n",
      "출력 값:  저 , 실제 값:  전\n",
      "출력 값:  저 , 실제 값:  전\n",
      "출력 값:  저 , 실제 값:  전\n",
      "출력 값:  삀 , 실제 값:  상\n",
      "출력 값:  삀 , 실제 값:  상\n",
      "출력 값:  삀 , 실제 값:  상\n",
      "출력 값:  삀 , 실제 값:  상\n",
      "출력 값:  삌 , 실제 값:  소\n",
      "출력 값:  삌 , 실제 값:  소\n",
      "출력 값:  삌 , 실제 값:  소\n",
      "출력 값:  삌 , 실제 값:  소\n",
      "출력 값:  부 , 실제 값:  부\n",
      "출력 값:  부 , 실제 값:  부\n",
      "출력 값:  릀 , 실제 값:  부\n",
      "출력 값:  부 , 실제 값:  부\n",
      "출력 값:  저 , 실제 값:  정\n",
      "출력 값:  저 , 실제 값:  정\n",
      "출력 값:  저 , 실제 값:  정\n",
      "출력 값:  저 , 실제 값:  정\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  외 , 실제 값:  인\n",
      "출력 값:  외 , 실제 값:  인\n",
      "출력 값:  외 , 실제 값:  인\n",
      "출력 값:  외 , 실제 값:  인\n",
      "출력 값:  왼 , 실제 값:  일\n",
      "출력 값:  왼 , 실제 값:  일\n",
      "출력 값:  왴 , 실제 값:  일\n",
      "출력 값:  왼 , 실제 값:  일\n",
      "출력 값:  귘 , 실제 값:  그\n",
      "출력 값:  귘 , 실제 값:  그\n",
      "출력 값:  귘 , 실제 값:  그\n",
      "출력 값:  귘 , 실제 값:  그\n",
      "출력 값:  주 , 실제 값:  주\n",
      "출력 값:  주 , 실제 값:  주\n",
      "출력 값:  주 , 실제 값:  주\n",
      "출력 값:  주 , 실제 값:  주\n",
      "출력 값:  걀 , 실제 값:  고\n",
      "출력 값:  걠 , 실제 값:  고\n",
      "출력 값:  곀 , 실제 값:  고\n",
      "출력 값:  곀 , 실제 값:  고\n",
      "출력 값:  냄 , 실제 값:  도\n",
      "출력 값:  냄 , 실제 값:  도\n",
      "출력 값:  냄 , 실제 값:  도\n",
      "출력 값:  냄 , 실제 값:  도\n",
      "출력 값:  혀 , 실제 값:  히\n",
      "출력 값:  혀 , 실제 값:  히\n",
      "출력 값:  혀 , 실제 값:  히\n",
      "출력 값:  혀 , 실제 값:  히\n",
      "출력 값:  구 , 실제 값:  구\n",
      "출력 값:  구 , 실제 값:  구\n",
      "출력 값:  구 , 실제 값:  구\n",
      "출력 값:  구 , 실제 값:  구\n",
      "출력 값:  렀 , 실제 값:  비\n",
      "출력 값:  렀 , 실제 값:  비\n",
      "출력 값:  끀 , 실제 값:  비\n",
      "출력 값:  렀 , 실제 값:  비\n",
      "출력 값:  챘 , 실제 값:  치\n",
      "출력 값:  챘 , 실제 값:  치\n",
      "출력 값:  챘 , 실제 값:  치\n",
      "출력 값:  챐 , 실제 값:  치\n",
      "출력 값:  룄 , 실제 값:  보\n",
      "출력 값:  별 , 실제 값:  보\n",
      "출력 값:  룄 , 실제 값:  보\n",
      "출력 값:  룄 , 실제 값:  보\n",
      "출력 값:  제 , 실제 값:  제\n",
      "출력 값:  제 , 실제 값:  제\n",
      "출력 값:  제 , 실제 값:  제\n",
      "출력 값:  쀜 , 실제 값:  제\n",
      "출력 값:  스 , 실제 값:  스\n",
      "출력 값:  스 , 실제 값:  스\n",
      "출력 값:  스 , 실제 값:  스\n",
      "출력 값:  스 , 실제 값:  스\n",
      "출력 값:  옄 , 실제 값:  오\n",
      "출력 값:  옄 , 실제 값:  오\n",
      "출력 값:  옄 , 실제 값:  오\n",
      "출력 값:  옄 , 실제 값:  오\n",
      "출력 값:  뤰 , 실제 값:  무\n",
      "출력 값:  뤰 , 실제 값:  무\n",
      "출력 값:  뤰 , 실제 값:  무\n",
      "출력 값:  뤰 , 실제 값:  무\n",
      "출력 값:  삈 , 실제 값:  생\n",
      "출력 값:  삈 , 실제 값:  생\n",
      "출력 값:  삈 , 실제 값:  생\n",
      "출력 값:  삈 , 실제 값:  생\n",
      "출력 값:  롈 , 실제 값:  마\n",
      "출력 값:  례 , 실제 값:  마\n",
      "출력 값:  롈 , 실제 값:  마\n",
      "출력 값:  례 , 실제 값:  마\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  쀌 , 실제 값:  서\n",
      "출력 값:  쀌 , 실제 값:  서\n",
      "출력 값:  쀌 , 실제 값:  서\n",
      "출력 값:  쀌 , 실제 값:  서\n",
      "출력 값:  쓰 , 실제 값:  연\n",
      "출력 값:  쓰 , 실제 값:  연\n",
      "출력 값:  쑰 , 실제 값:  연\n",
      "출력 값:  쓰 , 실제 값:  연\n",
      "출력 값:  롌 , 실제 값:  로\n",
      "출력 값:  롌 , 실제 값:  로\n",
      "출력 값:  롌 , 실제 값:  로\n",
      "출력 값:  롌 , 실제 값:  로\n",
      "출력 값:  낀 , 실제 값:  내\n",
      "출력 값:  낀 , 실제 값:  내\n",
      "출력 값:  낐 , 실제 값:  내\n",
      "출력 값:  낀 , 실제 값:  내\n",
      "출력 값:  쀠 , 실제 값:  성\n",
      "출력 값:  쀠 , 실제 값:  성\n",
      "출력 값:  쀠 , 실제 값:  성\n",
      "출력 값:  쀠 , 실제 값:  성\n",
      "출력 값:  푘 , 실제 값:  학\n",
      "출력 값:  푘 , 실제 값:  학\n",
      "출력 값:  푘 , 실제 값:  학\n",
      "출력 값:  푘 , 실제 값:  학\n",
      "출력 값:  실 , 실제 값:  실\n",
      "출력 값:  실 , 실제 값:  실\n",
      "출력 값:  실 , 실제 값:  실\n",
      "출력 값:  실 , 실제 값:  실\n",
      "출력 값:  화 , 실제 값:  화\n",
      "출력 값:  화 , 실제 값:  화\n",
      "출력 값:  화 , 실제 값:  화\n",
      "출력 값:  화 , 실제 값:  화\n",
      "출력 값:  좐 , 실제 값:  중\n",
      "출력 값:  좐 , 실제 값:  중\n",
      "출력 값:  좐 , 실제 값:  중\n",
      "출력 값:  좐 , 실제 값:  중\n",
      "출력 값:  곰 , 실제 값:  공\n",
      "출력 값:  곴 , 실제 값:  공\n",
      "출력 값:  ꣰ , 실제 값:  공\n",
      "출력 값:  곰 , 실제 값:  공\n",
      "출력 값:  푔 , 실제 값:  한\n",
      "출력 값:  푔 , 실제 값:  한\n",
      "출력 값:  푔 , 실제 값:  한\n",
      "출력 값:  푔 , 실제 값:  한\n",
      "출력 값:  굨 , 실제 값:  국\n",
      "출력 값:  굨 , 실제 값:  국\n",
      "출력 값:  굨 , 실제 값:  국\n",
      "출력 값:  굨 , 실제 값:  국\n",
      "출력 값:  푔 , 실제 값:  해\n",
      "출력 값:  푔 , 실제 값:  해\n",
      "출력 값:  푴 , 실제 값:  해\n",
      "출력 값:  푐 , 실제 값:  해\n",
      "출력 값:  가 , 실제 값:  관\n",
      "출력 값:  가 , 실제 값:  관\n",
      "출력 값:  가 , 실제 값:  관\n",
      "출력 값:  가 , 실제 값:  관\n",
      "출력 값:  옰 , 실제 값:  우\n",
      "출력 값:  옰 , 실제 값:  우\n",
      "출력 값:  옰 , 실제 값:  우\n",
      "출력 값:  옰 , 실제 값:  우\n",
      "출력 값:  쑤 , 실제 값:  여\n",
      "출력 값:  쐤 , 실제 값:  여\n",
      "출력 값:  쑤 , 실제 값:  여\n",
      "출력 값:  쑤 , 실제 값:  여\n",
      "출력 값:  싌 , 실제 값:  식\n",
      "출력 값:  싌 , 실제 값:  식\n",
      "출력 값:  싌 , 실제 값:  식\n",
      "출력 값:  싌 , 실제 값:  식\n",
      "출력 값:  뤰 , 실제 값:  문\n",
      "출력 값:  뤰 , 실제 값:  문\n",
      "출력 값:  뤰 , 실제 값:  문\n",
      "출력 값:  봰 , 실제 값:  문\n",
      "출력 값:  롰 , 실제 값:  미\n",
      "출력 값:  롰 , 실제 값:  미\n",
      "출력 값:  롰 , 실제 값:  미\n",
      "출력 값:  롰 , 실제 값:  미\n",
      "출력 값:  욠 , 실제 값:  용\n",
      "출력 값:  욠 , 실제 값:  용\n",
      "출력 값:  욈 , 실제 값:  용\n",
      "출력 값:  욠 , 실제 값:  용\n",
      "출력 값:  원 , 실제 값:  원\n",
      "출력 값:  원 , 실제 값:  원\n",
      "출력 값:  원 , 실제 값:  원\n",
      "출력 값:  원 , 실제 값:  원\n",
      "출력 값:  왘 , 실제 값:  의\n",
      "출력 값:  왘 , 실제 값:  의\n",
      "출력 값:  왘 , 실제 값:  의\n",
      "출력 값:  왘 , 실제 값:  의\n",
      "출력 값:  교 , 실제 값:  교\n",
      "출력 값:  교 , 실제 값:  교\n",
      "출력 값:  교 , 실제 값:  교\n",
      "출력 값:  교 , 실제 값:  교\n",
      "출력 값:  밀 , 실제 값:  방\n",
      "출력 값:  밀 , 실제 값:  방\n",
      "출력 값:  밀 , 실제 값:  방\n",
      "출력 값:  밀 , 실제 값:  방\n",
      "출력 값:  렀 , 실제 값:  바\n",
      "출력 값:  렀 , 실제 값:  바\n",
      "출력 값:  렐 , 실제 값:  바\n",
      "출력 값:  렐 , 실제 값:  바\n",
      "출력 값:  가 , 실제 값:  간\n",
      "출력 값:  가 , 실제 값:  간\n",
      "출력 값:  가 , 실제 값:  간\n",
      "출력 값:  가 , 실제 값:  간\n",
      "출력 값:  갰 , 실제 값:  거\n",
      "출력 값:  거 , 실제 값:  거\n",
      "출력 값:  갰 , 실제 값:  거\n",
      "출력 값:  갰 , 실제 값:  거\n",
      "출력 값:  옌 , 실제 값:  음\n",
      "출력 값:  옌 , 실제 값:  음\n",
      "출력 값:  옌 , 실제 값:  음\n",
      "출력 값:  옌 , 실제 값:  음\n",
      "출력 값:  밐 , 실제 값:  발\n",
      "출력 값:  밐 , 실제 값:  발\n",
      "출력 값:  밐 , 실제 값:  발\n",
      "출력 값:  밐 , 실제 값:  발\n",
      "출력 값:  뢀 , 실제 값:  모\n",
      "출력 값:  뢀 , 실제 값:  모\n",
      "출력 값:  뢀 , 실제 값:  모\n",
      "출력 값:  뢀 , 실제 값:  모\n",
      "출력 값:  겈 , 실제 값:  경\n",
      "출력 값:  겈 , 실제 값:  경\n",
      "출력 값:  갈 , 실제 값:  경\n",
      "출력 값:  겈 , 실제 값:  경\n",
      "출력 값:  조 , 실제 값:  조\n",
      "출력 값:  조 , 실제 값:  조\n",
      "출력 값:  조 , 실제 값:  조\n",
      "출력 값:  조 , 실제 값:  조\n",
      "출력 값:  옄 , 실제 값:  위\n",
      "출력 값:  옄 , 실제 값:  위\n",
      "출력 값:  옄 , 실제 값:  위\n",
      "출력 값:  옄 , 실제 값:  위\n",
      "출력 값:  저 , 실제 값:  저\n",
      "출력 값:  저 , 실제 값:  저\n",
      "출력 값:  저 , 실제 값:  저\n",
      "출력 값:  저 , 실제 값:  저\n",
      "출력 값:  룀 , 실제 값:  만\n",
      "출력 값:  룀 , 실제 값:  만\n",
      "출력 값:  룀 , 실제 값:  만\n",
      "출력 값:  룀 , 실제 값:  만\n",
      "출력 값:  개 , 실제 값:  개\n",
      "출력 값:  개 , 실제 값:  개\n",
      "출력 값:  개 , 실제 값:  개\n",
      "출력 값:  개 , 실제 값:  개\n",
      "출력 값:  쀨 , 실제 값:  세\n",
      "출력 값:  쀨 , 실제 값:  세\n",
      "출력 값:  쀨 , 실제 값:  세\n",
      "출력 값:  쀨 , 실제 값:  세\n",
      "출력 값:  요 , 실제 값:  요\n",
      "출력 값:  요 , 실제 값:  요\n",
      "출력 값:  요 , 실제 값:  요\n",
      "출력 값:  요 , 실제 값:  요\n",
      "출력 값:  밀 , 실제 값:  반\n",
      "출력 값:  밀 , 실제 값:  반\n",
      "출력 값:  밀 , 실제 값:  반\n",
      "출력 값:  밀 , 실제 값:  반\n",
      "출력 값:  뤸 , 실제 값:  물\n",
      "출력 값:  뤸 , 실제 값:  물\n",
      "출력 값:  뤼 , 실제 값:  물\n",
      "출력 값:  봼 , 실제 값:  물\n",
      "출력 값:  쑈 , 실제 값:  안\n",
      "출력 값:  쑈 , 실제 값:  안\n",
      "출력 값:  쑈 , 실제 값:  안\n",
      "출력 값:  쑈 , 실제 값:  안\n",
      "출력 값:  르 , 실제 값:  르\n",
      "출력 값:  르 , 실제 값:  르\n",
      "출력 값:  르 , 실제 값:  르\n",
      "출력 값:  르 , 실제 값:  르\n",
      "출력 값:  찈 , 실제 값:  차\n",
      "출력 값:  찈 , 실제 값:  차\n",
      "출력 값:  찈 , 실제 값:  차\n",
      "출력 값:  찈 , 실제 값:  차\n",
      "출력 값:  왘 , 실제 값:  외\n",
      "출력 값:  왘 , 실제 값:  외\n",
      "출력 값:  왘 , 실제 값:  외\n",
      "출력 값:  왘 , 실제 값:  외\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  분 , 실제 값:  분\n",
      "출력 값:  분 , 실제 값:  분\n",
      "출력 값:  분 , 실제 값:  분\n",
      "출력 값:  분 , 실제 값:  분\n",
      "출력 값:  냀 , 실제 값:  단\n",
      "출력 값:  냀 , 실제 값:  단\n",
      "출력 값:  냀 , 실제 값:  단\n",
      "출력 값:  냀 , 실제 값:  단\n",
      "출력 값:  킴 , 실제 값:  통\n",
      "출력 값:  킴 , 실제 값:  통\n",
      "출력 값:  킴 , 실제 값:  통\n",
      "출력 값:  킴 , 실제 값:  통\n",
      "출력 값:  옠 , 실제 값:  유\n",
      "출력 값:  옠 , 실제 값:  유\n",
      "출력 값:  옠 , 실제 값:  유\n",
      "출력 값:  옠 , 실제 값:  유\n",
      "출력 값:  쀠 , 실제 값:  선\n",
      "출력 값:  쀠 , 실제 값:  선\n",
      "출력 값:  쀠 , 실제 값:  선\n",
      "출력 값:  쀠 , 실제 값:  선\n",
      "출력 값:  삌 , 실제 값:  속\n",
      "출력 값:  삌 , 실제 값:  속\n",
      "출력 값:  삌 , 실제 값:  속\n",
      "출력 값:  삌 , 실제 값:  속\n",
      "출력 값:  계 , 실제 값:  계\n",
      "출력 값:  계 , 실제 값:  계\n",
      "출력 값:  계 , 실제 값:  계\n",
      "출력 값:  계 , 실제 값:  계\n",
      "출력 값:  쐀 , 실제 값:  예\n",
      "출력 값:  쐀 , 실제 값:  예\n",
      "출력 값:  쐀 , 실제 값:  예\n",
      "출력 값:  쐀 , 실제 값:  예\n",
      "출력 값:  걼 , 실제 값:  과\n",
      "출력 값:  걼 , 실제 값:  과\n",
      "출력 값:  걼 , 실제 값:  과\n",
      "출력 값:  걼 , 실제 값:  과\n",
      "출력 값:  불 , 실제 값:  불\n",
      "출력 값:  불 , 실제 값:  불\n",
      "출력 값:  불 , 실제 값:  불\n",
      "출력 값:  불 , 실제 값:  불\n",
      "출력 값:  갈 , 실제 값:  금\n",
      "출력 값:  갈 , 실제 값:  금\n",
      "출력 값:  갈 , 실제 값:  금\n",
      "출력 값:  갈 , 실제 값:  금\n",
      "출력 값:  냄 , 실제 값:  달\n",
      "출력 값:  냤 , 실제 값:  달\n",
      "출력 값:  냄 , 실제 값:  달\n",
      "출력 값:  냄 , 실제 값:  달\n",
      "출력 값:  욄 , 실제 값:  입\n",
      "출력 값:  욄 , 실제 값:  입\n",
      "출력 값:  욄 , 실제 값:  입\n",
      "출력 값:  욄 , 실제 값:  입\n",
      "출력 값:  저 , 실제 값:  점\n",
      "출력 값:  저 , 실제 값:  점\n",
      "출력 값:  저 , 실제 값:  점\n",
      "출력 값:  저 , 실제 값:  점\n",
      "출력 값:  닀 , 실제 값:  동\n",
      "출력 값:  틐 , 실제 값:  동\n",
      "출력 값:  닐 , 실제 값:  동\n",
      "출력 값:  닐 , 실제 값:  동\n",
      "출력 값:  가 , 실제 값:  감\n",
      "출력 값:  가 , 실제 값:  감\n",
      "출력 값:  가 , 실제 값:  감\n",
      "출력 값:  가 , 실제 값:  감\n",
      "출력 값:  천 , 실제 값:  출\n",
      "출력 값:  천 , 실제 값:  출\n",
      "출력 값:  천 , 실제 값:  출\n",
      "출력 값:  천 , 실제 값:  출\n",
      "출력 값:  품 , 실제 값:  행\n",
      "출력 값:  품 , 실제 값:  행\n",
      "출력 값:  품 , 실제 값:  행\n",
      "출력 값:  품 , 실제 값:  행\n",
      "출력 값:  삐 , 실제 값:  산\n",
      "출력 값:  삐 , 실제 값:  산\n",
      "출력 값:  삐 , 실제 값:  산\n",
      "출력 값:  쀰 , 실제 값:  산\n",
      "출력 값:  뒘 , 실제 값:  래\n",
      "출력 값:  나 , 실제 값:  래\n",
      "출력 값:  되 , 실제 값:  래\n",
      "출력 값:  뒘 , 실제 값:  래\n",
      "출력 값:  죀 , 실제 값:  진\n",
      "출력 값:  죀 , 실제 값:  진\n",
      "출력 값:  죀 , 실제 값:  진\n",
      "출력 값:  죀 , 실제 값:  진\n",
      "출력 값:  쒐 , 실제 값:  양\n",
      "출력 값:  쒐 , 실제 값:  양\n",
      "출력 값:  쒐 , 실제 값:  양\n",
      "출력 값:  쒐 , 실제 값:  양\n",
      "출력 값:  회 , 실제 값:  회\n",
      "출력 값:  회 , 실제 값:  회\n",
      "출력 값:  회 , 실제 값:  회\n",
      "출력 값:  회 , 실제 값:  회\n",
      "출력 값:  뢀 , 실제 값:  명\n",
      "출력 값:  뢀 , 실제 값:  명\n",
      "출력 값:  뢀 , 실제 값:  명\n",
      "출력 값:  뢀 , 실제 값:  명\n",
      "출력 값:  쒌 , 실제 값:  재\n",
      "출력 값:  쒌 , 실제 값:  재\n",
      "출력 값:  쒌 , 실제 값:  재\n",
      "출력 값:  쒌 , 실제 값:  재\n",
      "출력 값:  냘 , 실제 값:  당\n",
      "출력 값:  냐 , 실제 값:  당\n",
      "출력 값:  냘 , 실제 값:  당\n",
      "출력 값:  냘 , 실제 값:  당\n",
      "출력 값:  려 , 실제 값:  려\n",
      "출력 값:  려 , 실제 값:  려\n",
      "출력 값:  려 , 실제 값:  려\n",
      "출력 값:  려 , 실제 값:  려\n",
      "출력 값:  찀 , 실제 값:  초\n",
      "출력 값:  찀 , 실제 값:  초\n",
      "출력 값:  찀 , 실제 값:  초\n",
      "출력 값:  찀 , 실제 값:  초\n",
      "출력 값:  첔 , 실제 값:  체\n",
      "출력 값:  첔 , 실제 값:  체\n",
      "출력 값:  첔 , 실제 값:  체\n",
      "출력 값:  첔 , 실제 값:  체\n",
      "출력 값:  룐 , 실제 값:  말\n",
      "출력 값:  룐 , 실제 값:  말\n",
      "출력 값:  룐 , 실제 값:  말\n",
      "출력 값:  룐 , 실제 값:  말\n",
      "출력 값:  됬 , 실제 값:  러\n",
      "출력 값:  됬 , 실제 값:  러\n",
      "출력 값:  뀬 , 실제 값:  러\n",
      "출력 값:  됬 , 실제 값:  러\n",
      "출력 값:  였 , 실제 값:  영\n",
      "출력 값:  쐀 , 실제 값:  영\n",
      "출력 값:  였 , 실제 값:  영\n",
      "출력 값:  였 , 실제 값:  영\n",
      "출력 값:  거 , 실제 값:  건\n",
      "출력 값:  거 , 실제 값:  건\n",
      "출력 값:  거 , 실제 값:  건\n",
      "출력 값:  거 , 실제 값:  건\n",
      "출력 값:  가 , 실제 값:  강\n",
      "출력 값:  가 , 실제 값:  강\n",
      "출력 값:  감 , 실제 값:  강\n",
      "출력 값:  가 , 실제 값:  강\n",
      "출력 값:  둼 , 실제 값:  라\n",
      "출력 값:  둼 , 실제 값:  라\n",
      "출력 값:  둼 , 실제 값:  라\n",
      "출력 값:  둼 , 실제 값:  라\n",
      "출력 값:  쀤 , 실제 값:  설\n",
      "출력 값:  쀤 , 실제 값:  설\n",
      "출력 값:  쀤 , 실제 값:  설\n",
      "출력 값:  쀤 , 실제 값:  설\n",
      "출력 값:  죀 , 실제 값:  집\n",
      "출력 값:  죀 , 실제 값:  집\n",
      "출력 값:  죀 , 실제 값:  집\n",
      "출력 값:  죀 , 실제 값:  집\n",
      "출력 값:  첔 , 실제 값:  추\n",
      "출력 값:  첔 , 실제 값:  추\n",
      "출력 값:  첔 , 실제 값:  추\n",
      "출력 값:  첔 , 실제 값:  추\n",
      "출력 값:  쒐 , 실제 값:  작\n",
      "출력 값:  쒐 , 실제 값:  작\n",
      "출력 값:  쒐 , 실제 값:  작\n",
      "출력 값:  쒐 , 실제 값:  작\n",
      "출력 값:  낈 , 실제 값:  남\n",
      "출력 값:  낈 , 실제 값:  남\n",
      "출력 값:  낈 , 실제 값:  남\n",
      "출력 값:  낈 , 실제 값:  남\n",
      "출력 값:  가 , 실제 값:  각\n",
      "출력 값:  가 , 실제 값:  각\n",
      "출력 값:  가 , 실제 값:  각\n",
      "출력 값:  가 , 실제 값:  각\n",
      "출력 값:  냈 , 실제 값:  니\n",
      "출력 값:  냈 , 실제 값:  니\n",
      "출력 값:  냈 , 실제 값:  니\n",
      "출력 값:  냈 , 실제 값:  니\n",
      "출력 값:  퀼 , 실제 값:  피\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 값:  퀴 , 실제 값:  피\n",
      "출력 값:  퐼 , 실제 값:  피\n",
      "출력 값:  퀼 , 실제 값:  피\n",
      "출력 값:  낰 , 실제 값:  편\n",
      "출력 값:  낰 , 실제 값:  편\n",
      "출력 값:  낰 , 실제 값:  편\n",
      "출력 값:  낰 , 실제 값:  편\n",
      "출력 값:  룤 , 실제 값:  매\n",
      "출력 값:  룤 , 실제 값:  매\n",
      "출력 값:  룤 , 실제 값:  매\n",
      "출력 값:  룤 , 실제 값:  매\n",
      "출력 값:  근 , 실제 값:  근\n",
      "출력 값:  근 , 실제 값:  근\n",
      "출력 값:  근 , 실제 값:  근\n",
      "출력 값:  근 , 실제 값:  근\n",
      "출력 값:  뀰 , 실제 값:  터\n",
      "출력 값:  뀰 , 실제 값:  터\n",
      "출력 값:  뀰 , 실제 값:  터\n",
      "출력 값:  뀰 , 실제 값:  터\n",
      "출력 값:  쓄 , 실제 값:  업\n",
      "출력 값:  쓄 , 실제 값:  업\n",
      "출력 값:  쓄 , 실제 값:  업\n",
      "출력 값:  쓄 , 실제 값:  업\n",
      "출력 값:  렀 , 실제 값:  버\n",
      "출력 값:  렀 , 실제 값:  버\n",
      "출력 값:  렀 , 실제 값:  버\n",
      "출력 값:  렀 , 실제 값:  버\n",
      "출력 값:  쀌 , 실제 값:  석\n",
      "출력 값:  쀌 , 실제 값:  석\n",
      "출력 값:  쀌 , 실제 값:  석\n",
      "출력 값:  쀌 , 실제 값:  석\n",
      "출력 값:  냄 , 실제 값:  들\n",
      "출력 값:  듄 , 실제 값:  들\n",
      "출력 값:  듄 , 실제 값:  들\n",
      "출력 값:  듄 , 실제 값:  들\n",
      "출력 값:  저 , 실제 값:  절\n",
      "출력 값:  저 , 실제 값:  절\n",
      "출력 값:  저 , 실제 값:  절\n",
      "출력 값:  저 , 실제 값:  절\n",
      "출력 값:  갰 , 실제 값:  결\n",
      "출력 값:  갰 , 실제 값:  결\n",
      "출력 값:  갰 , 실제 값:  결\n",
      "출력 값:  갰 , 실제 값:  결\n",
      "출력 값:  쑼 , 실제 값:  약\n",
      "출력 값:  쑼 , 실제 값:  약\n",
      "출력 값:  쑼 , 실제 값:  약\n",
      "출력 값:  쑼 , 실제 값:  약\n",
      "출력 값:  죀 , 실제 값:  직\n",
      "출력 값:  죀 , 실제 값:  직\n",
      "출력 값:  죀 , 실제 값:  직\n",
      "출력 값:  죀 , 실제 값:  직\n",
      "출력 값:  낀 , 실제 값:  날\n",
      "출력 값:  낀 , 실제 값:  날\n",
      "출력 값:  낀 , 실제 값:  날\n",
      "출력 값:  낀 , 실제 값:  날\n",
      "출력 값:  삐 , 실제 값:  손\n",
      "출력 값:  쀐 , 실제 값:  손\n",
      "출력 값:  삐 , 실제 값:  손\n",
      "출력 값:  삐 , 실제 값:  손\n",
      "출력 값:  렰 , 실제 값:  배\n",
      "출력 값:  렰 , 실제 값:  배\n",
      "출력 값:  렰 , 실제 값:  배\n",
      "출력 값:  렰 , 실제 값:  배\n",
      "출력 값:  보 , 실제 값:  복\n",
      "출력 값:  보 , 실제 값:  복\n",
      "출력 값:  보 , 실제 값:  복\n",
      "출력 값:  보 , 실제 값:  복\n",
      "출력 값:  혐 , 실제 값:  호\n",
      "출력 값:  혐 , 실제 값:  호\n",
      "출력 값:  혐 , 실제 값:  호\n",
      "출력 값:  혐 , 실제 값:  호\n",
      "출력 값:  푔 , 실제 값:  표\n",
      "출력 값:  푔 , 실제 값:  표\n",
      "출력 값:  푔 , 실제 값:  표\n",
      "출력 값:  푔 , 실제 값:  표\n",
      "출력 값:  려 , 실제 값:  력\n",
      "출력 값:  려 , 실제 값:  력\n",
      "출력 값:  렬 , 실제 값:  력\n",
      "출력 값:  려 , 실제 값:  력\n",
      "출력 값:  킈 , 실제 값:  품\n",
      "출력 값:  킀 , 실제 값:  품\n",
      "출력 값:  킈 , 실제 값:  품\n",
      "출력 값:  쒈 , 실제 값:  품\n",
      "출력 값:  쓄 , 실제 값:  없\n",
      "출력 값:  쓄 , 실제 값:  없\n",
      "출력 값:  쓄 , 실제 값:  없\n",
      "출력 값:  쓄 , 실제 값:  없\n",
      "출력 값:  삈 , 실제 값:  색\n",
      "출력 값:  삈 , 실제 값:  색\n",
      "출력 값:  삈 , 실제 값:  색\n",
      "출력 값:  삈 , 실제 값:  색\n",
      "출력 값:  튰 , 실제 값:  트\n",
      "출력 값:  튰 , 실제 값:  트\n",
      "출력 값:  튰 , 실제 값:  트\n",
      "출력 값:  튰 , 실제 값:  트\n",
      "출력 값:  활 , 실제 값:  활\n",
      "출력 값:  활 , 실제 값:  활\n",
      "출력 값:  활 , 실제 값:  활\n",
      "출력 값:  활 , 실제 값:  활\n",
      "출력 값:  옸 , 실제 값:  울\n",
      "출력 값:  울 , 실제 값:  울\n",
      "출력 값:  우 , 실제 값:  울\n",
      "출력 값:  울 , 실제 값:  울\n",
      "출력 값:  삈 , 실제 값:  새\n",
      "출력 값:  삈 , 실제 값:  새\n",
      "출력 값:  삈 , 실제 값:  새\n",
      "출력 값:  삈 , 실제 값:  새\n",
      "출력 값:  렰 , 실제 값:  머\n",
      "출력 값:  렸 , 실제 값:  머\n",
      "출력 값:  렰 , 실제 값:  머\n",
      "출력 값:  렰 , 실제 값:  머\n",
      "출력 값:  살 , 실제 값:  살\n",
      "출력 값:  살 , 실제 값:  살\n",
      "출력 값:  살 , 실제 값:  살\n",
      "출력 값:  살 , 실제 값:  살\n",
      "출력 값:  좄 , 실제 값:  종\n",
      "출력 값:  좄 , 실제 값:  종\n",
      "출력 값:  좄 , 실제 값:  종\n",
      "출력 값:  좄 , 실제 값:  종\n",
      "출력 값:  찀 , 실제 값:  청\n",
      "출력 값:  찠 , 실제 값:  청\n",
      "출력 값:  찠 , 실제 값:  청\n",
      "출력 값:  찀 , 실제 값:  청\n",
      "출력 값:  현 , 실제 값:  현\n",
      "출력 값:  퐄 , 실제 값:  현\n",
      "출력 값:  퐄 , 실제 값:  현\n",
      "출력 값:  현 , 실제 값:  현\n",
      "출력 값:  옰 , 실제 값:  운\n",
      "출력 값:  옰 , 실제 값:  운\n",
      "출력 값:  옰 , 실제 값:  운\n",
      "출력 값:  옰 , 실제 값:  운\n",
      "출력 값:  냀 , 실제 값:  타\n",
      "출력 값:  냀 , 실제 값:  타\n",
      "출력 값:  냀 , 실제 값:  타\n",
      "출력 값:  냀 , 실제 값:  타\n",
      "출력 값:  뀐 , 실제 값:  판\n",
      "출력 값:  뀀 , 실제 값:  판\n",
      "출력 값:  뀀 , 실제 값:  판\n",
      "출력 값:  뀐 , 실제 값:  판\n",
      "출력 값:  월 , 실제 값:  월\n",
      "출력 값:  월 , 실제 값:  월\n",
      "출력 값:  월 , 실제 값:  월\n",
      "출력 값:  월 , 실제 값:  월\n",
      "출력 값:  롰 , 실제 값:  면\n",
      "출력 값:  롰 , 실제 값:  면\n",
      "출력 값:  롴 , 실제 값:  면\n",
      "출력 값:  롰 , 실제 값:  면\n",
      "출력 값:  냬 , 실제 값:  럽\n",
      "출력 값:  듬 , 실제 값:  럽\n",
      "출력 값:  듬 , 실제 값:  럽\n",
      "출력 값:  듬 , 실제 값:  럽\n",
      "출력 값:  뢄 , 실제 값:  름\n",
      "출력 값:  뢄 , 실제 값:  름\n",
      "출력 값:  뢄 , 실제 값:  름\n",
      "출력 값:  뢄 , 실제 값:  름\n",
      "출력 값:  찐 , 실제 값:  참\n",
      "출력 값:  찐 , 실제 값:  참\n",
      "출력 값:  찐 , 실제 값:  참\n",
      "출력 값:  찐 , 실제 값:  참\n",
      "출력 값:  퐐 , 실제 값:  형\n",
      "출력 값:  퐔 , 실제 값:  형\n",
      "출력 값:  혐 , 실제 값:  형\n",
      "출력 값:  퐔 , 실제 값:  형\n",
      "출력 값:  화 , 실제 값:  확\n",
      "출력 값:  화 , 실제 값:  확\n",
      "출력 값:  화 , 실제 값:  확\n",
      "출력 값:  화 , 실제 값:  확\n",
      "출력 값:  룐 , 실제 값:  망\n",
      "출력 값:  룐 , 실제 값:  망\n",
      "출력 값:  룐 , 실제 값:  망\n",
      "출력 값:  룀 , 실제 값:  망\n",
      "출력 값:  쑼 , 실제 값:  야\n",
      "출력 값:  쑼 , 실제 값:  야\n",
      "출력 값:  쑼 , 실제 값:  야\n",
      "출력 값:  쑼 , 실제 값:  야\n",
      "출력 값:  좼 , 실제 값:  쪽\n",
      "출력 값:  슼 , 실제 값:  쪽\n",
      "출력 값:  좼 , 실제 값:  쪽\n",
      "출력 값:  쪼 , 실제 값:  쪽\n",
      "출력 값:  욄 , 실제 값:  임\n",
      "출력 값:  욄 , 실제 값:  임\n",
      "출력 값:  욄 , 실제 값:  임\n",
      "출력 값:  욄 , 실제 값:  임\n",
      "출력 값:  탄 , 실제 값:  포\n",
      "출력 값:  탄 , 실제 값:  포\n",
      "출력 값:  틄 , 실제 값:  포\n",
      "출력 값:  틄 , 실제 값:  포\n",
      "출력 값:  룰 , 실제 값:  민\n",
      "출력 값:  룰 , 실제 값:  민\n",
      "출력 값:  룰 , 실제 값:  민\n",
      "출력 값:  룰 , 실제 값:  민\n",
      "출력 값:  쓬 , 실제 값:  역\n",
      "출력 값:  쓬 , 실제 값:  역\n",
      "출력 값:  쓬 , 실제 값:  역\n",
      "출력 값:  쓤 , 실제 값:  역\n",
      "출력 값:  뢨 , 실제 값:  목\n",
      "출력 값:  뢨 , 실제 값:  목\n",
      "출력 값:  뢨 , 실제 값:  목\n",
      "출력 값:  뢨 , 실제 값:  목\n",
      "출력 값:  숐 , 실제 값:  순\n",
      "출력 값:  숐 , 실제 값:  순\n",
      "출력 값:  숐 , 실제 값:  순\n",
      "출력 값:  수 , 실제 값:  순\n",
      "출력 값:  변 , 실제 값:  별\n",
      "출력 값:  변 , 실제 값:  별\n",
      "출력 값:  변 , 실제 값:  별\n",
      "출력 값:  변 , 실제 값:  별\n",
      "출력 값:  술 , 실제 값:  술\n",
      "출력 값:  술 , 실제 값:  술\n",
      "출력 값:  술 , 실제 값:  술\n",
      "출력 값:  술 , 실제 값:  술\n",
      "출력 값:  갈 , 실제 값:  급\n",
      "출력 값:  갈 , 실제 값:  급\n",
      "출력 값:  갈 , 실제 값:  급\n",
      "출력 값:  갈 , 실제 값:  급\n",
      "출력 값:  올 , 실제 값:  올\n",
      "출력 값:  올 , 실제 값:  올\n",
      "출력 값:  올 , 실제 값:  올\n",
      "출력 값:  올 , 실제 값:  올\n",
      "출력 값:  끐 , 실제 값:  두\n",
      "출력 값:  끐 , 실제 값:  두\n",
      "출력 값:  두 , 실제 값:  두\n",
      "출력 값:  끐 , 실제 값:  두\n",
      "출력 값:  냀 , 실제 값:  평\n",
      "출력 값:  낀 , 실제 값:  평\n",
      "출력 값:  냀 , 실제 값:  평\n",
      "출력 값:  냀 , 실제 값:  평\n",
      "출력 값:  끀 , 실제 값:  년\n",
      "출력 값:  끀 , 실제 값:  년\n",
      "출력 값:  끄 , 실제 값:  년\n",
      "출력 값:  끀 , 실제 값:  년\n",
      "출력 값:  밀 , 실제 값:  번\n",
      "출력 값:  밀 , 실제 값:  번\n",
      "출력 값:  밀 , 실제 값:  번\n",
      "출력 값:  밀 , 실제 값:  번\n",
      "출력 값:  죀 , 실제 값:  질\n",
      "출력 값:  죀 , 실제 값:  질\n",
      "출력 값:  죀 , 실제 값:  질\n",
      "출력 값:  죀 , 실제 값:  질\n",
      "출력 값:  끰 , 실제 값:  데\n",
      "출력 값:  끰 , 실제 값:  데\n",
      "출력 값:  끰 , 실제 값:  데\n",
      "출력 값:  끰 , 실제 값:  데\n",
      "출력 값:  냄 , 실제 값:  담\n",
      "출력 값:  냔 , 실제 값:  담\n",
      "출력 값:  냄 , 실제 값:  담\n",
      "출력 값:  냄 , 실제 값:  담\n",
      "출력 값:  뀈 , 실제 값:  너\n",
      "출력 값:  뀈 , 실제 값:  너\n",
      "출력 값:  뀈 , 실제 값:  너\n",
      "출력 값:  뀈 , 실제 값:  너\n",
      "출력 값:  낀 , 실제 값:  늘\n",
      "출력 값:  낈 , 실제 값:  늘\n",
      "출력 값:  낀 , 실제 값:  늘\n",
      "출력 값:  낀 , 실제 값:  늘\n",
      "출력 값:  찐 , 실제 값:  천\n",
      "출력 값:  찐 , 실제 값:  천\n",
      "출력 값:  찐 , 실제 값:  천\n",
      "출력 값:  찐 , 실제 값:  천\n",
      "출력 값:  듔 , 실제 값:  드\n",
      "출력 값:  듔 , 실제 값:  드\n",
      "출력 값:  듔 , 실제 값:  드\n",
      "출력 값:  듔 , 실제 값:  드\n",
      "출력 값:  그 , 실제 값:  극\n",
      "출력 값:  그 , 실제 값:  극\n",
      "출력 값:  그 , 실제 값:  극\n",
      "출력 값:  그 , 실제 값:  극\n",
      "출력 값:  후 , 실제 값:  후\n",
      "출력 값:  후 , 실제 값:  후\n",
      "출력 값:  후 , 실제 값:  후\n",
      "출력 값:  후 , 실제 값:  후\n",
      "출력 값:  뀌 , 실제 값:  파\n",
      "출력 값:  뀌 , 실제 값:  파\n",
      "출력 값:  뀌 , 실제 값:  파\n",
      "출력 값:  뀀 , 실제 값:  파\n",
      "출력 값:  갨 , 실제 값:  격\n",
      "출력 값:  갨 , 실제 값:  격\n",
      "출력 값:  갨 , 실제 값:  격\n",
      "출력 값:  갨 , 실제 값:  격\n",
      "출력 값:  좜 , 실제 값:  증\n",
      "출력 값:  좜 , 실제 값:  증\n",
      "출력 값:  좜 , 실제 값:  증\n",
      "출력 값:  좌 , 실제 값:  증\n",
      "출력 값:  뀄 , 실제 값:  디\n",
      "출력 값:  뀄 , 실제 값:  디\n",
      "출력 값:  뀄 , 실제 값:  디\n",
      "출력 값:  뀄 , 실제 값:  디\n",
      "출력 값:  큀 , 실제 값:  필\n",
      "출력 값:  큀 , 실제 값:  필\n",
      "출력 값:  끀 , 실제 값:  필\n",
      "출력 값:  끀 , 실제 값:  필\n",
      "출력 값:  혰 , 실제 값:  혼\n",
      "출력 값:  혰 , 실제 값:  혼\n",
      "출력 값:  혴 , 실제 값:  혼\n",
      "출력 값:  혰 , 실제 값:  혼\n",
      "출력 값:  슴 , 실제 값:  습\n",
      "출력 값:  슴 , 실제 값:  습\n",
      "출력 값:  슴 , 실제 값:  습\n",
      "출력 값:  슴 , 실제 값:  습\n",
      "출력 값:  끈 , 실제 값:  노\n",
      "출력 값:  끈 , 실제 값:  노\n",
      "출력 값:  끘 , 실제 값:  노\n",
      "출력 값:  끈 , 실제 값:  노\n",
      "출력 값:  챜 , 실제 값:  최\n",
      "출력 값:  챜 , 실제 값:  최\n",
      "출력 값:  챜 , 실제 값:  최\n",
      "출력 값:  챜 , 실제 값:  최\n",
      "출력 값:  찐 , 실제 값:  창\n",
      "출력 값:  찐 , 실제 값:  창\n",
      "출력 값:  찐 , 실제 값:  창\n",
      "출력 값:  찐 , 실제 값:  창\n",
      "출력 값:  볰 , 실제 값:  본\n",
      "출력 값:  볰 , 실제 값:  본\n",
      "출력 값:  볰 , 실제 값:  본\n",
      "출력 값:  볰 , 실제 값:  본\n",
      "출력 값:  저 , 실제 값:  접\n",
      "출력 값:  저 , 실제 값:  접\n",
      "출력 값:  저 , 실제 값:  접\n",
      "출력 값:  저 , 실제 값:  접\n",
      "출력 값:  걨 , 실제 값:  깨\n",
      "출력 값:  걨 , 실제 값:  깨\n",
      "출력 값:  걨 , 실제 값:  깨\n",
      "출력 값:  걨 , 실제 값:  깨\n",
      "출력 값:  갰 , 실제 값:  길\n",
      "출력 값:  갸 , 실제 값:  길\n",
      "출력 값:  갰 , 실제 값:  길\n",
      "출력 값:  갸 , 실제 값:  길\n",
      "출력 값:  퐄 , 실제 값:  프\n",
      "출력 값:  퐄 , 실제 값:  프\n",
      "출력 값:  퐄 , 실제 값:  프\n",
      "출력 값:  퐄 , 실제 값:  프\n",
      "출력 값:  벀 , 실제 값:  법\n",
      "출력 값:  벀 , 실제 값:  법\n",
      "출력 값:  벀 , 실제 값:  법\n",
      "출력 값:  벀 , 실제 값:  법\n",
      "출력 값:  루 , 실제 값:  루\n",
      "출력 값:  루 , 실제 값:  루\n",
      "출력 값:  루 , 실제 값:  루\n",
      "출력 값:  루 , 실제 값:  루\n",
      "출력 값:  뀀 , 실제 값:  눈\n",
      "출력 값:  뀀 , 실제 값:  눈\n",
      "출력 값:  뀀 , 실제 값:  눈\n",
      "출력 값:  뀀 , 실제 값:  눈\n",
      "출력 값:  홐 , 실제 값:  환\n",
      "출력 값:  홐 , 실제 값:  환\n",
      "출력 값:  환 , 실제 값:  환\n",
      "출력 값:  홐 , 실제 값:  환\n",
      "출력 값:  였 , 실제 값:  은\n",
      "출력 값:  였 , 실제 값:  은\n",
      "출력 값:  였 , 실제 값:  은\n",
      "출력 값:  였 , 실제 값:  은\n",
      "출력 값:  쒀 , 실제 값:  잠\n",
      "출력 값:  쒀 , 실제 값:  잠\n",
      "출력 값:  쒀 , 실제 값:  잠\n",
      "출력 값:  쒀 , 실제 값:  잠\n",
      "출력 값:  쑜 , 실제 값:  앞\n",
      "출력 값:  쑜 , 실제 값:  앞\n",
      "출력 값:  쑜 , 실제 값:  앞\n",
      "출력 값:  쑜 , 실제 값:  앞\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  챔 , 실제 값:  코\n",
      "출력 값:  굔 , 실제 값:  코\n",
      "출력 값:  챔 , 실제 값:  코\n",
      "출력 값:  챔 , 실제 값:  코\n",
      "출력 값:  밀 , 실제 값:  밤\n",
      "출력 값:  밀 , 실제 값:  밤\n",
      "출력 값:  밀 , 실제 값:  밤\n",
      "출력 값:  밀 , 실제 값:  밤\n",
      "출력 값:  칀 , 실제 값:  침\n",
      "출력 값:  칀 , 실제 값:  침\n",
      "출력 값:  칀 , 실제 값:  침\n",
      "출력 값:  칀 , 실제 값:  침\n",
      "출력 값:  낀 , 실제 값:  난\n",
      "출력 값:  낀 , 실제 값:  난\n",
      "출력 값:  낈 , 실제 값:  난\n",
      "출력 값:  낀 , 실제 값:  난\n",
      "출력 값:  워 , 실제 값:  워\n",
      "출력 값:  워 , 실제 값:  워\n",
      "출력 값:  워 , 실제 값:  워\n",
      "출력 값:  워 , 실제 값:  워\n",
      "출력 값:  괸 , 실제 값:  꾸\n",
      "출력 값:  괸 , 실제 값:  꾸\n",
      "출력 값:  괸 , 실제 값:  꾸\n",
      "출력 값:  괸 , 실제 값:  꾸\n",
      "출력 값:  채 , 실제 값:  책\n",
      "출력 값:  채 , 실제 값:  책\n",
      "출력 값:  찄 , 실제 값:  책\n",
      "출력 값:  채 , 실제 값:  책\n",
      "출력 값:  쓴 , 실제 값:  열\n",
      "출력 값:  쓴 , 실제 값:  열\n",
      "출력 값:  쓴 , 실제 값:  열\n",
      "출력 값:  쓴 , 실제 값:  열\n",
      "출력 값:  닄 , 실제 값:  독\n",
      "출력 값:  닄 , 실제 값:  독\n",
      "출력 값:  닄 , 실제 값:  독\n",
      "출력 값:  닄 , 실제 값:  독\n",
      "출력 값:  찠 , 실제 값:  철\n",
      "출력 값:  찠 , 실제 값:  철\n",
      "출력 값:  찠 , 실제 값:  철\n",
      "출력 값:  찠 , 실제 값:  철\n",
      "출력 값:  산 , 실제 값:  쓰\n",
      "출력 값:  산 , 실제 값:  쓰\n",
      "출력 값:  산 , 실제 값:  쓰\n",
      "출력 값:  산 , 실제 값:  쓰\n",
      "출력 값:  군 , 실제 값:  군\n",
      "출력 값:  군 , 실제 값:  군\n",
      "출력 값:  군 , 실제 값:  군\n",
      "출력 값:  군 , 실제 값:  군\n",
      "출력 값:  둼 , 실제 값:  락\n",
      "출력 값:  둼 , 실제 값:  락\n",
      "출력 값:  둼 , 실제 값:  락\n",
      "출력 값:  둼 , 실제 값:  락\n",
      "출력 값:  쒀 , 실제 값:  잡\n",
      "출력 값:  쒀 , 실제 값:  잡\n",
      "출력 값:  쒀 , 실제 값:  잡\n",
      "출력 값:  쒀 , 실제 값:  잡\n",
      "출력 값:  벀 , 실제 값:  벌\n",
      "출력 값:  벀 , 실제 값:  벌\n",
      "출력 값:  벀 , 실제 값:  벌\n",
      "출력 값:  밀 , 실제 값:  벌\n",
      "출력 값:  욀 , 실제 값:  움\n",
      "출력 값:  욀 , 실제 값:  움\n",
      "출력 값:  욀 , 실제 값:  움\n",
      "출력 값:  움 , 실제 값:  움\n",
      "출력 값:  처 , 실제 값:  처\n",
      "출력 값:  처 , 실제 값:  처\n",
      "출력 값:  처 , 실제 값:  처\n",
      "출력 값:  첐 , 실제 값:  처\n",
      "출력 값:  푈 , 실제 값:  합\n",
      "출력 값:  푈 , 실제 값:  합\n",
      "출력 값:  푈 , 실제 값:  합\n",
      "출력 값:  푈 , 실제 값:  합\n",
      "출력 값:  쀨 , 실제 값:  씨\n",
      "출력 값:  쀨 , 실제 값:  씨\n",
      "출력 값:  쀨 , 실제 값:  씨\n",
      "출력 값:  쀨 , 실제 값:  씨\n",
      "출력 값:  킀 , 실제 값:  토\n",
      "출력 값:  킀 , 실제 값:  토\n",
      "출력 값:  킀 , 실제 값:  토\n",
      "출력 값:  킀 , 실제 값:  토\n",
      "출력 값:  풄 , 실제 값:  향\n",
      "출력 값:  풄 , 실제 값:  향\n",
      "출력 값:  풄 , 실제 값:  향\n",
      "출력 값:  풄 , 실제 값:  향\n",
      "출력 값:  삌 , 실제 값:  삼\n",
      "출력 값:  삌 , 실제 값:  삼\n",
      "출력 값:  삌 , 실제 값:  삼\n",
      "출력 값:  삌 , 실제 값:  삼\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  낀 , 실제 값:  능\n",
      "출력 값:  낀 , 실제 값:  능\n",
      "출력 값:  낀 , 실제 값:  능\n",
      "출력 값:  낀 , 실제 값:  능\n",
      "출력 값:  냄 , 실제 값:  답\n",
      "출력 값:  냄 , 실제 값:  답\n",
      "출력 값:  냄 , 실제 값:  답\n",
      "출력 값:  냄 , 실제 값:  답\n",
      "출력 값:  옠 , 실제 값:  육\n",
      "출력 값:  옠 , 실제 값:  육\n",
      "출력 값:  옠 , 실제 값:  육\n",
      "출력 값:  옠 , 실제 값:  육\n",
      "출력 값:  키 , 실제 값:  키\n",
      "출력 값:  키 , 실제 값:  키\n",
      "출력 값:  키 , 실제 값:  키\n",
      "출력 값:  키 , 실제 값:  키\n",
      "출력 값:  냈 , 실제 값:  님\n",
      "출력 값:  냈 , 실제 값:  님\n",
      "출력 값:  냈 , 실제 값:  님\n",
      "출력 값:  냈 , 실제 값:  님\n",
      "출력 값:  튰 , 실제 값:  특\n",
      "출력 값:  튰 , 실제 값:  특\n",
      "출력 값:  튰 , 실제 값:  특\n",
      "출력 값:  튰 , 실제 값:  특\n",
      "출력 값:  련 , 실제 값:  먹\n",
      "출력 값:  련 , 실제 값:  먹\n",
      "출력 값:  련 , 실제 값:  먹\n",
      "출력 값:  렸 , 실제 값:  먹\n",
      "출력 값:  갈 , 실제 값:  갈\n",
      "출력 값:  갈 , 실제 값:  갈\n",
      "출력 값:  갈 , 실제 값:  갈\n",
      "출력 값:  갈 , 실제 값:  갈\n",
      "출력 값:  삠 , 실제 값:  송\n",
      "출력 값:  삠 , 실제 값:  송\n",
      "출력 값:  삠 , 실제 값:  송\n",
      "출력 값:  삠 , 실제 값:  송\n",
      "출력 값:  쒐 , 실제 값:  잘\n",
      "출력 값:  쒘 , 실제 값:  잘\n",
      "출력 값:  쒐 , 실제 값:  잘\n",
      "출력 값:  쒘 , 실제 값:  잘\n",
      "출력 값:  끀 , 실제 값:  녀\n",
      "출력 값:  끀 , 실제 값:  녀\n",
      "출력 값:  끀 , 실제 값:  녀\n",
      "출력 값:  끀 , 실제 값:  녀\n",
      "출력 값:  퓘 , 실제 값:  험\n",
      "출력 값:  퓘 , 실제 값:  험\n",
      "출력 값:  퓘 , 실제 값:  험\n",
      "출력 값:  푘 , 실제 값:  험\n",
      "출력 값:  료 , 실제 값:  료\n",
      "출력 값:  료 , 실제 값:  료\n",
      "출력 값:  료 , 실제 값:  료\n",
      "출력 값:  료 , 실제 값:  료\n",
      "출력 값:  냘 , 실제 값:  태\n",
      "출력 값:  냜 , 실제 값:  태\n",
      "출력 값:  냜 , 실제 값:  태\n",
      "출력 값:  태 , 실제 값:  태\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for j, sample in enumerate(dataloader):\n",
    "        x = sample['image']\n",
    "        y = sample['label']\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        for i in range(len(output)):\n",
    "            print(\"출력 값: \", decode_from_bin(output[i].tolist()),\n",
    "                  \", 실제 값: \", decode_from_bin(y[i].tolist()))\n",
    "            #print(\"실제 값: \", output[i].tolist(),\n",
    "            #      \", 출력 값: \", y[i].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Testing Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 값:  끤 , 실제 값:  다\n",
      "출력 값:  끤 , 실제 값:  다\n",
      "출력 값:  끤 , 실제 값:  다\n",
      "출력 값:  푐 , 실제 값:  하\n",
      "출력 값:  푐 , 실제 값:  하\n",
      "출력 값:  푐 , 실제 값:  하\n",
      "출력 값:  푐 , 실제 값:  하\n",
      "출력 값:  죀 , 실제 값:  지\n",
      "출력 값:  죀 , 실제 값:  지\n",
      "출력 값:  죀 , 실제 값:  지\n",
      "출력 값:  죀 , 실제 값:  지\n",
      "출력 값:  왴 , 실제 값:  이\n",
      "출력 값:  왴 , 실제 값:  이\n",
      "출력 값:  왴 , 실제 값:  이\n",
      "출력 값:  왴 , 실제 값:  이\n",
      "출력 값:  갰 , 실제 값:  기\n",
      "출력 값:  갰 , 실제 값:  기\n",
      "출력 값:  갰 , 실제 값:  기\n",
      "출력 값:  갰 , 실제 값:  기\n",
      "출력 값:  렬 , 실제 값:  리\n",
      "출력 값:  렬 , 실제 값:  리\n",
      "출력 값:  렬 , 실제 값:  리\n",
      "출력 값:  렬 , 실제 값:  리\n",
      "출력 값:  가 , 실제 값:  가\n",
      "출력 값:  가 , 실제 값:  가\n",
      "출력 값:  가 , 실제 값:  가\n",
      "출력 값:  가 , 실제 값:  가\n",
      "출력 값:  삌 , 실제 값:  사\n",
      "출력 값:  삌 , 실제 값:  사\n",
      "출력 값:  삌 , 실제 값:  사\n",
      "출력 값:  삌 , 실제 값:  사\n",
      "출력 값:  쒀 , 실제 값:  자\n",
      "출력 값:  쒐 , 실제 값:  자\n",
      "출력 값:  쒐 , 실제 값:  자\n",
      "출력 값:  쒀 , 실제 값:  자\n",
      "출력 값:  뀀 , 실제 값:  대\n",
      "출력 값:  뀀 , 실제 값:  대\n",
      "출력 값:  뀀 , 실제 값:  대\n",
      "출력 값:  뀀 , 실제 값:  대\n",
      "출력 값:  저 , 실제 값:  적\n",
      "출력 값:  저 , 실제 값:  적\n",
      "출력 값:  저 , 실제 값:  적\n",
      "출력 값:  ꠀ , 실제 값:  적\n",
      "출력 값:  쐴 , 실제 값:  어\n",
      "출력 값:  쐴 , 실제 값:  어\n",
      "출력 값:  쐴 , 실제 값:  어\n",
      "출력 값:  쐴 , 실제 값:  어\n",
      "출력 값:  쑄 , 실제 값:  아\n",
      "출력 값:  쑄 , 실제 값:  아\n",
      "출력 값:  쑄 , 실제 값:  아\n",
      "출력 값:  쑄 , 실제 값:  아\n",
      "출력 값:  싌 , 실제 값:  시\n",
      "출력 값:  싌 , 실제 값:  시\n",
      "출력 값:  싌 , 실제 값:  시\n",
      "출력 값:  싌 , 실제 값:  시\n",
      "출력 값:  쒀 , 실제 값:  장\n",
      "출력 값:  쒀 , 실제 값:  장\n",
      "출력 값:  쒀 , 실제 값:  장\n",
      "출력 값:  쒀 , 실제 값:  장\n",
      "출력 값:  수 , 실제 값:  수\n",
      "출력 값:  수 , 실제 값:  수\n",
      "출력 값:  쀘 , 실제 값:  수\n",
      "출력 값:  수 , 실제 값:  수\n",
      "출력 값:  되 , 실제 값:  되\n",
      "출력 값:  뀘 , 실제 값:  되\n",
      "출력 값:  되 , 실제 값:  되\n",
      "출력 값:  뀘 , 실제 값:  되\n",
      "출력 값:  저 , 실제 값:  전\n",
      "출력 값:  저 , 실제 값:  전\n",
      "출력 값:  저 , 실제 값:  전\n",
      "출력 값:  저 , 실제 값:  전\n",
      "출력 값:  삀 , 실제 값:  상\n",
      "출력 값:  삀 , 실제 값:  상\n",
      "출력 값:  삀 , 실제 값:  상\n",
      "출력 값:  삀 , 실제 값:  상\n",
      "출력 값:  삌 , 실제 값:  소\n",
      "출력 값:  삌 , 실제 값:  소\n",
      "출력 값:  삌 , 실제 값:  소\n",
      "출력 값:  삌 , 실제 값:  소\n",
      "출력 값:  부 , 실제 값:  부\n",
      "출력 값:  부 , 실제 값:  부\n",
      "출력 값:  릀 , 실제 값:  부\n",
      "출력 값:  부 , 실제 값:  부\n",
      "출력 값:  저 , 실제 값:  정\n",
      "출력 값:  저 , 실제 값:  정\n",
      "출력 값:  저 , 실제 값:  정\n",
      "출력 값:  저 , 실제 값:  정\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  외 , 실제 값:  인\n",
      "출력 값:  외 , 실제 값:  인\n",
      "출력 값:  외 , 실제 값:  인\n",
      "출력 값:  외 , 실제 값:  인\n",
      "출력 값:  왼 , 실제 값:  일\n",
      "출력 값:  왼 , 실제 값:  일\n",
      "출력 값:  왴 , 실제 값:  일\n",
      "출력 값:  왼 , 실제 값:  일\n",
      "출력 값:  귘 , 실제 값:  그\n",
      "출력 값:  귘 , 실제 값:  그\n",
      "출력 값:  귘 , 실제 값:  그\n",
      "출력 값:  귘 , 실제 값:  그\n",
      "출력 값:  주 , 실제 값:  주\n",
      "출력 값:  주 , 실제 값:  주\n",
      "출력 값:  주 , 실제 값:  주\n",
      "출력 값:  주 , 실제 값:  주\n",
      "출력 값:  걀 , 실제 값:  고\n",
      "출력 값:  걠 , 실제 값:  고\n",
      "출력 값:  곀 , 실제 값:  고\n",
      "출력 값:  곀 , 실제 값:  고\n",
      "출력 값:  냄 , 실제 값:  도\n",
      "출력 값:  냄 , 실제 값:  도\n",
      "출력 값:  냄 , 실제 값:  도\n",
      "출력 값:  냄 , 실제 값:  도\n",
      "출력 값:  혀 , 실제 값:  히\n",
      "출력 값:  혀 , 실제 값:  히\n",
      "출력 값:  혀 , 실제 값:  히\n",
      "출력 값:  혀 , 실제 값:  히\n",
      "출력 값:  구 , 실제 값:  구\n",
      "출력 값:  구 , 실제 값:  구\n",
      "출력 값:  구 , 실제 값:  구\n",
      "출력 값:  구 , 실제 값:  구\n",
      "출력 값:  렀 , 실제 값:  비\n",
      "출력 값:  렀 , 실제 값:  비\n",
      "출력 값:  끀 , 실제 값:  비\n",
      "출력 값:  렀 , 실제 값:  비\n",
      "출력 값:  챘 , 실제 값:  치\n",
      "출력 값:  챘 , 실제 값:  치\n",
      "출력 값:  챘 , 실제 값:  치\n",
      "출력 값:  챐 , 실제 값:  치\n",
      "출력 값:  룄 , 실제 값:  보\n",
      "출력 값:  별 , 실제 값:  보\n",
      "출력 값:  룄 , 실제 값:  보\n",
      "출력 값:  룄 , 실제 값:  보\n",
      "출력 값:  제 , 실제 값:  제\n",
      "출력 값:  제 , 실제 값:  제\n",
      "출력 값:  제 , 실제 값:  제\n",
      "출력 값:  쀜 , 실제 값:  제\n",
      "출력 값:  스 , 실제 값:  스\n",
      "출력 값:  스 , 실제 값:  스\n",
      "출력 값:  스 , 실제 값:  스\n",
      "출력 값:  스 , 실제 값:  스\n",
      "출력 값:  옄 , 실제 값:  오\n",
      "출력 값:  옄 , 실제 값:  오\n",
      "출력 값:  옄 , 실제 값:  오\n",
      "출력 값:  옄 , 실제 값:  오\n",
      "출력 값:  뤰 , 실제 값:  무\n",
      "출력 값:  뤰 , 실제 값:  무\n",
      "출력 값:  뤰 , 실제 값:  무\n",
      "출력 값:  뤰 , 실제 값:  무\n",
      "출력 값:  삈 , 실제 값:  생\n",
      "출력 값:  삈 , 실제 값:  생\n",
      "출력 값:  삈 , 실제 값:  생\n",
      "출력 값:  삈 , 실제 값:  생\n",
      "출력 값:  롈 , 실제 값:  마\n",
      "출력 값:  례 , 실제 값:  마\n",
      "출력 값:  롈 , 실제 값:  마\n",
      "출력 값:  례 , 실제 값:  마\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  쀌 , 실제 값:  서\n",
      "출력 값:  쀌 , 실제 값:  서\n",
      "출력 값:  쀌 , 실제 값:  서\n",
      "출력 값:  쀌 , 실제 값:  서\n",
      "출력 값:  쓰 , 실제 값:  연\n",
      "출력 값:  쓰 , 실제 값:  연\n",
      "출력 값:  쑰 , 실제 값:  연\n",
      "출력 값:  쓰 , 실제 값:  연\n",
      "출력 값:  롌 , 실제 값:  로\n",
      "출력 값:  롌 , 실제 값:  로\n",
      "출력 값:  롌 , 실제 값:  로\n",
      "출력 값:  롌 , 실제 값:  로\n",
      "출력 값:  낀 , 실제 값:  내\n",
      "출력 값:  낀 , 실제 값:  내\n",
      "출력 값:  낐 , 실제 값:  내\n",
      "출력 값:  낀 , 실제 값:  내\n",
      "출력 값:  쀠 , 실제 값:  성\n",
      "출력 값:  쀠 , 실제 값:  성\n",
      "출력 값:  쀠 , 실제 값:  성\n",
      "출력 값:  쀠 , 실제 값:  성\n",
      "출력 값:  푘 , 실제 값:  학\n",
      "출력 값:  푘 , 실제 값:  학\n",
      "출력 값:  푘 , 실제 값:  학\n",
      "출력 값:  푘 , 실제 값:  학\n",
      "출력 값:  실 , 실제 값:  실\n",
      "출력 값:  실 , 실제 값:  실\n",
      "출력 값:  실 , 실제 값:  실\n",
      "출력 값:  실 , 실제 값:  실\n",
      "출력 값:  화 , 실제 값:  화\n",
      "출력 값:  화 , 실제 값:  화\n",
      "출력 값:  화 , 실제 값:  화\n",
      "출력 값:  화 , 실제 값:  화\n",
      "출력 값:  좐 , 실제 값:  중\n",
      "출력 값:  좐 , 실제 값:  중\n",
      "출력 값:  좐 , 실제 값:  중\n",
      "출력 값:  좐 , 실제 값:  중\n",
      "출력 값:  곰 , 실제 값:  공\n",
      "출력 값:  곴 , 실제 값:  공\n",
      "출력 값:  ꣰ , 실제 값:  공\n",
      "출력 값:  곰 , 실제 값:  공\n",
      "출력 값:  푔 , 실제 값:  한\n",
      "출력 값:  푔 , 실제 값:  한\n",
      "출력 값:  푔 , 실제 값:  한\n",
      "출력 값:  푔 , 실제 값:  한\n",
      "출력 값:  굨 , 실제 값:  국\n",
      "출력 값:  굨 , 실제 값:  국\n",
      "출력 값:  굨 , 실제 값:  국\n",
      "출력 값:  굨 , 실제 값:  국\n",
      "출력 값:  푔 , 실제 값:  해\n",
      "출력 값:  푔 , 실제 값:  해\n",
      "출력 값:  푴 , 실제 값:  해\n",
      "출력 값:  푐 , 실제 값:  해\n",
      "출력 값:  가 , 실제 값:  관\n",
      "출력 값:  가 , 실제 값:  관\n",
      "출력 값:  가 , 실제 값:  관\n",
      "출력 값:  가 , 실제 값:  관\n",
      "출력 값:  옰 , 실제 값:  우\n",
      "출력 값:  옰 , 실제 값:  우\n",
      "출력 값:  옰 , 실제 값:  우\n",
      "출력 값:  옰 , 실제 값:  우\n",
      "출력 값:  쑤 , 실제 값:  여\n",
      "출력 값:  쐤 , 실제 값:  여\n",
      "출력 값:  쑤 , 실제 값:  여\n",
      "출력 값:  쑤 , 실제 값:  여\n",
      "출력 값:  싌 , 실제 값:  식\n",
      "출력 값:  싌 , 실제 값:  식\n",
      "출력 값:  싌 , 실제 값:  식\n",
      "출력 값:  싌 , 실제 값:  식\n",
      "출력 값:  뤰 , 실제 값:  문\n",
      "출력 값:  뤰 , 실제 값:  문\n",
      "출력 값:  뤰 , 실제 값:  문\n",
      "출력 값:  봰 , 실제 값:  문\n",
      "출력 값:  롰 , 실제 값:  미\n",
      "출력 값:  롰 , 실제 값:  미\n",
      "출력 값:  롰 , 실제 값:  미\n",
      "출력 값:  롰 , 실제 값:  미\n",
      "출력 값:  욠 , 실제 값:  용\n",
      "출력 값:  욠 , 실제 값:  용\n",
      "출력 값:  욈 , 실제 값:  용\n",
      "출력 값:  욠 , 실제 값:  용\n",
      "출력 값:  원 , 실제 값:  원\n",
      "출력 값:  원 , 실제 값:  원\n",
      "출력 값:  원 , 실제 값:  원\n",
      "출력 값:  원 , 실제 값:  원\n",
      "출력 값:  왘 , 실제 값:  의\n",
      "출력 값:  왘 , 실제 값:  의\n",
      "출력 값:  왘 , 실제 값:  의\n",
      "출력 값:  왘 , 실제 값:  의\n",
      "출력 값:  교 , 실제 값:  교\n",
      "출력 값:  교 , 실제 값:  교\n",
      "출력 값:  교 , 실제 값:  교\n",
      "출력 값:  교 , 실제 값:  교\n",
      "출력 값:  밀 , 실제 값:  방\n",
      "출력 값:  밀 , 실제 값:  방\n",
      "출력 값:  밀 , 실제 값:  방\n",
      "출력 값:  밀 , 실제 값:  방\n",
      "출력 값:  렀 , 실제 값:  바\n",
      "출력 값:  렀 , 실제 값:  바\n",
      "출력 값:  렐 , 실제 값:  바\n",
      "출력 값:  렐 , 실제 값:  바\n",
      "출력 값:  가 , 실제 값:  간\n",
      "출력 값:  가 , 실제 값:  간\n",
      "출력 값:  가 , 실제 값:  간\n",
      "출력 값:  가 , 실제 값:  간\n",
      "출력 값:  갰 , 실제 값:  거\n",
      "출력 값:  거 , 실제 값:  거\n",
      "출력 값:  갰 , 실제 값:  거\n",
      "출력 값:  갰 , 실제 값:  거\n",
      "출력 값:  옌 , 실제 값:  음\n",
      "출력 값:  옌 , 실제 값:  음\n",
      "출력 값:  옌 , 실제 값:  음\n",
      "출력 값:  옌 , 실제 값:  음\n",
      "출력 값:  밐 , 실제 값:  발\n",
      "출력 값:  밐 , 실제 값:  발\n",
      "출력 값:  밐 , 실제 값:  발\n",
      "출력 값:  밐 , 실제 값:  발\n",
      "출력 값:  뢀 , 실제 값:  모\n",
      "출력 값:  뢀 , 실제 값:  모\n",
      "출력 값:  뢀 , 실제 값:  모\n",
      "출력 값:  뢀 , 실제 값:  모\n",
      "출력 값:  겈 , 실제 값:  경\n",
      "출력 값:  겈 , 실제 값:  경\n",
      "출력 값:  갈 , 실제 값:  경\n",
      "출력 값:  겈 , 실제 값:  경\n",
      "출력 값:  조 , 실제 값:  조\n",
      "출력 값:  조 , 실제 값:  조\n",
      "출력 값:  조 , 실제 값:  조\n",
      "출력 값:  조 , 실제 값:  조\n",
      "출력 값:  옄 , 실제 값:  위\n",
      "출력 값:  옄 , 실제 값:  위\n",
      "출력 값:  옄 , 실제 값:  위\n",
      "출력 값:  옄 , 실제 값:  위\n",
      "출력 값:  저 , 실제 값:  저\n",
      "출력 값:  저 , 실제 값:  저\n",
      "출력 값:  저 , 실제 값:  저\n",
      "출력 값:  저 , 실제 값:  저\n",
      "출력 값:  룀 , 실제 값:  만\n",
      "출력 값:  룀 , 실제 값:  만\n",
      "출력 값:  룀 , 실제 값:  만\n",
      "출력 값:  룀 , 실제 값:  만\n",
      "출력 값:  개 , 실제 값:  개\n",
      "출력 값:  개 , 실제 값:  개\n",
      "출력 값:  개 , 실제 값:  개\n",
      "출력 값:  개 , 실제 값:  개\n",
      "출력 값:  쀨 , 실제 값:  세\n",
      "출력 값:  쀨 , 실제 값:  세\n",
      "출력 값:  쀨 , 실제 값:  세\n",
      "출력 값:  쀨 , 실제 값:  세\n",
      "출력 값:  요 , 실제 값:  요\n",
      "출력 값:  요 , 실제 값:  요\n",
      "출력 값:  요 , 실제 값:  요\n",
      "출력 값:  요 , 실제 값:  요\n",
      "출력 값:  밀 , 실제 값:  반\n",
      "출력 값:  밀 , 실제 값:  반\n",
      "출력 값:  밀 , 실제 값:  반\n",
      "출력 값:  밀 , 실제 값:  반\n",
      "출력 값:  뤸 , 실제 값:  물\n",
      "출력 값:  뤸 , 실제 값:  물\n",
      "출력 값:  뤼 , 실제 값:  물\n",
      "출력 값:  봼 , 실제 값:  물\n",
      "출력 값:  쑈 , 실제 값:  안\n",
      "출력 값:  쑈 , 실제 값:  안\n",
      "출력 값:  쑈 , 실제 값:  안\n",
      "출력 값:  쑈 , 실제 값:  안\n",
      "출력 값:  르 , 실제 값:  르\n",
      "출력 값:  르 , 실제 값:  르\n",
      "출력 값:  르 , 실제 값:  르\n",
      "출력 값:  르 , 실제 값:  르\n",
      "출력 값:  찈 , 실제 값:  차\n",
      "출력 값:  찈 , 실제 값:  차\n",
      "출력 값:  찈 , 실제 값:  차\n",
      "출력 값:  찈 , 실제 값:  차\n",
      "출력 값:  왘 , 실제 값:  외\n",
      "출력 값:  왘 , 실제 값:  외\n",
      "출력 값:  왘 , 실제 값:  외\n",
      "출력 값:  왘 , 실제 값:  외\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  분 , 실제 값:  분\n",
      "출력 값:  분 , 실제 값:  분\n",
      "출력 값:  분 , 실제 값:  분\n",
      "출력 값:  분 , 실제 값:  분\n",
      "출력 값:  냀 , 실제 값:  단\n",
      "출력 값:  냀 , 실제 값:  단\n",
      "출력 값:  냀 , 실제 값:  단\n",
      "출력 값:  냀 , 실제 값:  단\n",
      "출력 값:  킴 , 실제 값:  통\n",
      "출력 값:  킴 , 실제 값:  통\n",
      "출력 값:  킴 , 실제 값:  통\n",
      "출력 값:  킴 , 실제 값:  통\n",
      "출력 값:  옠 , 실제 값:  유\n",
      "출력 값:  옠 , 실제 값:  유\n",
      "출력 값:  옠 , 실제 값:  유\n",
      "출력 값:  옠 , 실제 값:  유\n",
      "출력 값:  쀠 , 실제 값:  선\n",
      "출력 값:  쀠 , 실제 값:  선\n",
      "출력 값:  쀠 , 실제 값:  선\n",
      "출력 값:  쀠 , 실제 값:  선\n",
      "출력 값:  삌 , 실제 값:  속\n",
      "출력 값:  삌 , 실제 값:  속\n",
      "출력 값:  삌 , 실제 값:  속\n",
      "출력 값:  삌 , 실제 값:  속\n",
      "출력 값:  계 , 실제 값:  계\n",
      "출력 값:  계 , 실제 값:  계\n",
      "출력 값:  계 , 실제 값:  계\n",
      "출력 값:  계 , 실제 값:  계\n",
      "출력 값:  쐀 , 실제 값:  예\n",
      "출력 값:  쐀 , 실제 값:  예\n",
      "출력 값:  쐀 , 실제 값:  예\n",
      "출력 값:  쐀 , 실제 값:  예\n",
      "출력 값:  걼 , 실제 값:  과\n",
      "출력 값:  걼 , 실제 값:  과\n",
      "출력 값:  걼 , 실제 값:  과\n",
      "출력 값:  걼 , 실제 값:  과\n",
      "출력 값:  불 , 실제 값:  불\n",
      "출력 값:  불 , 실제 값:  불\n",
      "출력 값:  불 , 실제 값:  불\n",
      "출력 값:  불 , 실제 값:  불\n",
      "출력 값:  갈 , 실제 값:  금\n",
      "출력 값:  갈 , 실제 값:  금\n",
      "출력 값:  갈 , 실제 값:  금\n",
      "출력 값:  갈 , 실제 값:  금\n",
      "출력 값:  냄 , 실제 값:  달\n",
      "출력 값:  냤 , 실제 값:  달\n",
      "출력 값:  냄 , 실제 값:  달\n",
      "출력 값:  냄 , 실제 값:  달\n",
      "출력 값:  욄 , 실제 값:  입\n",
      "출력 값:  욄 , 실제 값:  입\n",
      "출력 값:  욄 , 실제 값:  입\n",
      "출력 값:  욄 , 실제 값:  입\n",
      "출력 값:  저 , 실제 값:  점\n",
      "출력 값:  저 , 실제 값:  점\n",
      "출력 값:  저 , 실제 값:  점\n",
      "출력 값:  저 , 실제 값:  점\n",
      "출력 값:  닀 , 실제 값:  동\n",
      "출력 값:  틐 , 실제 값:  동\n",
      "출력 값:  닐 , 실제 값:  동\n",
      "출력 값:  닐 , 실제 값:  동\n",
      "출력 값:  가 , 실제 값:  감\n",
      "출력 값:  가 , 실제 값:  감\n",
      "출력 값:  가 , 실제 값:  감\n",
      "출력 값:  가 , 실제 값:  감\n",
      "출력 값:  천 , 실제 값:  출\n",
      "출력 값:  천 , 실제 값:  출\n",
      "출력 값:  천 , 실제 값:  출\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 값:  천 , 실제 값:  출\n",
      "출력 값:  품 , 실제 값:  행\n",
      "출력 값:  품 , 실제 값:  행\n",
      "출력 값:  품 , 실제 값:  행\n",
      "출력 값:  품 , 실제 값:  행\n",
      "출력 값:  삐 , 실제 값:  산\n",
      "출력 값:  삐 , 실제 값:  산\n",
      "출력 값:  삐 , 실제 값:  산\n",
      "출력 값:  쀰 , 실제 값:  산\n",
      "출력 값:  뒘 , 실제 값:  래\n",
      "출력 값:  나 , 실제 값:  래\n",
      "출력 값:  되 , 실제 값:  래\n",
      "출력 값:  뒘 , 실제 값:  래\n",
      "출력 값:  죀 , 실제 값:  진\n",
      "출력 값:  죀 , 실제 값:  진\n",
      "출력 값:  죀 , 실제 값:  진\n",
      "출력 값:  죀 , 실제 값:  진\n",
      "출력 값:  쒐 , 실제 값:  양\n",
      "출력 값:  쒐 , 실제 값:  양\n",
      "출력 값:  쒐 , 실제 값:  양\n",
      "출력 값:  쒐 , 실제 값:  양\n",
      "출력 값:  회 , 실제 값:  회\n",
      "출력 값:  회 , 실제 값:  회\n",
      "출력 값:  회 , 실제 값:  회\n",
      "출력 값:  회 , 실제 값:  회\n",
      "출력 값:  뢀 , 실제 값:  명\n",
      "출력 값:  뢀 , 실제 값:  명\n",
      "출력 값:  뢀 , 실제 값:  명\n",
      "출력 값:  뢀 , 실제 값:  명\n",
      "출력 값:  쒌 , 실제 값:  재\n",
      "출력 값:  쒌 , 실제 값:  재\n",
      "출력 값:  쒌 , 실제 값:  재\n",
      "출력 값:  쒌 , 실제 값:  재\n",
      "출력 값:  냘 , 실제 값:  당\n",
      "출력 값:  냐 , 실제 값:  당\n",
      "출력 값:  냘 , 실제 값:  당\n",
      "출력 값:  냘 , 실제 값:  당\n",
      "출력 값:  려 , 실제 값:  려\n",
      "출력 값:  려 , 실제 값:  려\n",
      "출력 값:  려 , 실제 값:  려\n",
      "출력 값:  려 , 실제 값:  려\n",
      "출력 값:  찀 , 실제 값:  초\n",
      "출력 값:  찀 , 실제 값:  초\n",
      "출력 값:  찀 , 실제 값:  초\n",
      "출력 값:  찀 , 실제 값:  초\n",
      "출력 값:  첔 , 실제 값:  체\n",
      "출력 값:  첔 , 실제 값:  체\n",
      "출력 값:  첔 , 실제 값:  체\n",
      "출력 값:  첔 , 실제 값:  체\n",
      "출력 값:  룐 , 실제 값:  말\n",
      "출력 값:  룐 , 실제 값:  말\n",
      "출력 값:  룐 , 실제 값:  말\n",
      "출력 값:  룐 , 실제 값:  말\n",
      "출력 값:  됬 , 실제 값:  러\n",
      "출력 값:  됬 , 실제 값:  러\n",
      "출력 값:  뀬 , 실제 값:  러\n",
      "출력 값:  됬 , 실제 값:  러\n",
      "출력 값:  였 , 실제 값:  영\n",
      "출력 값:  쐀 , 실제 값:  영\n",
      "출력 값:  였 , 실제 값:  영\n",
      "출력 값:  였 , 실제 값:  영\n",
      "출력 값:  거 , 실제 값:  건\n",
      "출력 값:  거 , 실제 값:  건\n",
      "출력 값:  거 , 실제 값:  건\n",
      "출력 값:  거 , 실제 값:  건\n",
      "출력 값:  가 , 실제 값:  강\n",
      "출력 값:  가 , 실제 값:  강\n",
      "출력 값:  감 , 실제 값:  강\n",
      "출력 값:  가 , 실제 값:  강\n",
      "출력 값:  둼 , 실제 값:  라\n",
      "출력 값:  둼 , 실제 값:  라\n",
      "출력 값:  둼 , 실제 값:  라\n",
      "출력 값:  둼 , 실제 값:  라\n",
      "출력 값:  쀤 , 실제 값:  설\n",
      "출력 값:  쀤 , 실제 값:  설\n",
      "출력 값:  쀤 , 실제 값:  설\n",
      "출력 값:  쀤 , 실제 값:  설\n",
      "출력 값:  죀 , 실제 값:  집\n",
      "출력 값:  죀 , 실제 값:  집\n",
      "출력 값:  죀 , 실제 값:  집\n",
      "출력 값:  죀 , 실제 값:  집\n",
      "출력 값:  첔 , 실제 값:  추\n",
      "출력 값:  첔 , 실제 값:  추\n",
      "출력 값:  첔 , 실제 값:  추\n",
      "출력 값:  첔 , 실제 값:  추\n",
      "출력 값:  쒐 , 실제 값:  작\n",
      "출력 값:  쒐 , 실제 값:  작\n",
      "출력 값:  쒐 , 실제 값:  작\n",
      "출력 값:  쒐 , 실제 값:  작\n",
      "출력 값:  낈 , 실제 값:  남\n",
      "출력 값:  낈 , 실제 값:  남\n",
      "출력 값:  낈 , 실제 값:  남\n",
      "출력 값:  낈 , 실제 값:  남\n",
      "출력 값:  가 , 실제 값:  각\n",
      "출력 값:  가 , 실제 값:  각\n",
      "출력 값:  가 , 실제 값:  각\n",
      "출력 값:  가 , 실제 값:  각\n",
      "출력 값:  냈 , 실제 값:  니\n",
      "출력 값:  냈 , 실제 값:  니\n",
      "출력 값:  냈 , 실제 값:  니\n",
      "출력 값:  냈 , 실제 값:  니\n",
      "출력 값:  퀼 , 실제 값:  피\n",
      "출력 값:  퀴 , 실제 값:  피\n",
      "출력 값:  퐼 , 실제 값:  피\n",
      "출력 값:  퀼 , 실제 값:  피\n",
      "출력 값:  낰 , 실제 값:  편\n",
      "출력 값:  낰 , 실제 값:  편\n",
      "출력 값:  낰 , 실제 값:  편\n",
      "출력 값:  낰 , 실제 값:  편\n",
      "출력 값:  룤 , 실제 값:  매\n",
      "출력 값:  룤 , 실제 값:  매\n",
      "출력 값:  룤 , 실제 값:  매\n",
      "출력 값:  룤 , 실제 값:  매\n",
      "출력 값:  근 , 실제 값:  근\n",
      "출력 값:  근 , 실제 값:  근\n",
      "출력 값:  근 , 실제 값:  근\n",
      "출력 값:  근 , 실제 값:  근\n",
      "출력 값:  뀰 , 실제 값:  터\n",
      "출력 값:  뀰 , 실제 값:  터\n",
      "출력 값:  뀰 , 실제 값:  터\n",
      "출력 값:  뀰 , 실제 값:  터\n",
      "출력 값:  쓄 , 실제 값:  업\n",
      "출력 값:  쓄 , 실제 값:  업\n",
      "출력 값:  쓄 , 실제 값:  업\n",
      "출력 값:  쓄 , 실제 값:  업\n",
      "출력 값:  렀 , 실제 값:  버\n",
      "출력 값:  렀 , 실제 값:  버\n",
      "출력 값:  렀 , 실제 값:  버\n",
      "출력 값:  렀 , 실제 값:  버\n",
      "출력 값:  쀌 , 실제 값:  석\n",
      "출력 값:  쀌 , 실제 값:  석\n",
      "출력 값:  쀌 , 실제 값:  석\n",
      "출력 값:  쀌 , 실제 값:  석\n",
      "출력 값:  냄 , 실제 값:  들\n",
      "출력 값:  듄 , 실제 값:  들\n",
      "출력 값:  듄 , 실제 값:  들\n",
      "출력 값:  듄 , 실제 값:  들\n",
      "출력 값:  저 , 실제 값:  절\n",
      "출력 값:  저 , 실제 값:  절\n",
      "출력 값:  저 , 실제 값:  절\n",
      "출력 값:  저 , 실제 값:  절\n",
      "출력 값:  갰 , 실제 값:  결\n",
      "출력 값:  갰 , 실제 값:  결\n",
      "출력 값:  갰 , 실제 값:  결\n",
      "출력 값:  갰 , 실제 값:  결\n",
      "출력 값:  쑼 , 실제 값:  약\n",
      "출력 값:  쑼 , 실제 값:  약\n",
      "출력 값:  쑼 , 실제 값:  약\n",
      "출력 값:  쑼 , 실제 값:  약\n",
      "출력 값:  죀 , 실제 값:  직\n",
      "출력 값:  죀 , 실제 값:  직\n",
      "출력 값:  죀 , 실제 값:  직\n",
      "출력 값:  죀 , 실제 값:  직\n",
      "출력 값:  낀 , 실제 값:  날\n",
      "출력 값:  낀 , 실제 값:  날\n",
      "출력 값:  낀 , 실제 값:  날\n",
      "출력 값:  낀 , 실제 값:  날\n",
      "출력 값:  삐 , 실제 값:  손\n",
      "출력 값:  쀐 , 실제 값:  손\n",
      "출력 값:  삐 , 실제 값:  손\n",
      "출력 값:  삐 , 실제 값:  손\n",
      "출력 값:  렰 , 실제 값:  배\n",
      "출력 값:  렰 , 실제 값:  배\n",
      "출력 값:  렰 , 실제 값:  배\n",
      "출력 값:  렰 , 실제 값:  배\n",
      "출력 값:  보 , 실제 값:  복\n",
      "출력 값:  보 , 실제 값:  복\n",
      "출력 값:  보 , 실제 값:  복\n",
      "출력 값:  보 , 실제 값:  복\n",
      "출력 값:  혐 , 실제 값:  호\n",
      "출력 값:  혐 , 실제 값:  호\n",
      "출력 값:  혐 , 실제 값:  호\n",
      "출력 값:  혐 , 실제 값:  호\n",
      "출력 값:  푔 , 실제 값:  표\n",
      "출력 값:  푔 , 실제 값:  표\n",
      "출력 값:  푔 , 실제 값:  표\n",
      "출력 값:  푔 , 실제 값:  표\n",
      "출력 값:  려 , 실제 값:  력\n",
      "출력 값:  려 , 실제 값:  력\n",
      "출력 값:  렬 , 실제 값:  력\n",
      "출력 값:  려 , 실제 값:  력\n",
      "출력 값:  킈 , 실제 값:  품\n",
      "출력 값:  킀 , 실제 값:  품\n",
      "출력 값:  킈 , 실제 값:  품\n",
      "출력 값:  쒈 , 실제 값:  품\n",
      "출력 값:  쓄 , 실제 값:  없\n",
      "출력 값:  쓄 , 실제 값:  없\n",
      "출력 값:  쓄 , 실제 값:  없\n",
      "출력 값:  쓄 , 실제 값:  없\n",
      "출력 값:  삈 , 실제 값:  색\n",
      "출력 값:  삈 , 실제 값:  색\n",
      "출력 값:  삈 , 실제 값:  색\n",
      "출력 값:  삈 , 실제 값:  색\n",
      "출력 값:  튰 , 실제 값:  트\n",
      "출력 값:  튰 , 실제 값:  트\n",
      "출력 값:  튰 , 실제 값:  트\n",
      "출력 값:  튰 , 실제 값:  트\n",
      "출력 값:  활 , 실제 값:  활\n",
      "출력 값:  활 , 실제 값:  활\n",
      "출력 값:  활 , 실제 값:  활\n",
      "출력 값:  활 , 실제 값:  활\n",
      "출력 값:  옸 , 실제 값:  울\n",
      "출력 값:  울 , 실제 값:  울\n",
      "출력 값:  우 , 실제 값:  울\n",
      "출력 값:  울 , 실제 값:  울\n",
      "출력 값:  삈 , 실제 값:  새\n",
      "출력 값:  삈 , 실제 값:  새\n",
      "출력 값:  삈 , 실제 값:  새\n",
      "출력 값:  삈 , 실제 값:  새\n",
      "출력 값:  렰 , 실제 값:  머\n",
      "출력 값:  렸 , 실제 값:  머\n",
      "출력 값:  렰 , 실제 값:  머\n",
      "출력 값:  렰 , 실제 값:  머\n",
      "출력 값:  살 , 실제 값:  살\n",
      "출력 값:  살 , 실제 값:  살\n",
      "출력 값:  살 , 실제 값:  살\n",
      "출력 값:  살 , 실제 값:  살\n",
      "출력 값:  좄 , 실제 값:  종\n",
      "출력 값:  좄 , 실제 값:  종\n",
      "출력 값:  좄 , 실제 값:  종\n",
      "출력 값:  좄 , 실제 값:  종\n",
      "출력 값:  찀 , 실제 값:  청\n",
      "출력 값:  찠 , 실제 값:  청\n",
      "출력 값:  찠 , 실제 값:  청\n",
      "출력 값:  찀 , 실제 값:  청\n",
      "출력 값:  현 , 실제 값:  현\n",
      "출력 값:  퐄 , 실제 값:  현\n",
      "출력 값:  퐄 , 실제 값:  현\n",
      "출력 값:  현 , 실제 값:  현\n",
      "출력 값:  옰 , 실제 값:  운\n",
      "출력 값:  옰 , 실제 값:  운\n",
      "출력 값:  옰 , 실제 값:  운\n",
      "출력 값:  옰 , 실제 값:  운\n",
      "출력 값:  냀 , 실제 값:  타\n",
      "출력 값:  냀 , 실제 값:  타\n",
      "출력 값:  냀 , 실제 값:  타\n",
      "출력 값:  냀 , 실제 값:  타\n",
      "출력 값:  뀐 , 실제 값:  판\n",
      "출력 값:  뀀 , 실제 값:  판\n",
      "출력 값:  뀀 , 실제 값:  판\n",
      "출력 값:  뀐 , 실제 값:  판\n",
      "출력 값:  월 , 실제 값:  월\n",
      "출력 값:  월 , 실제 값:  월\n",
      "출력 값:  월 , 실제 값:  월\n",
      "출력 값:  월 , 실제 값:  월\n",
      "출력 값:  롰 , 실제 값:  면\n",
      "출력 값:  롰 , 실제 값:  면\n",
      "출력 값:  롴 , 실제 값:  면\n",
      "출력 값:  롰 , 실제 값:  면\n",
      "출력 값:  냬 , 실제 값:  럽\n",
      "출력 값:  듬 , 실제 값:  럽\n",
      "출력 값:  듬 , 실제 값:  럽\n",
      "출력 값:  듬 , 실제 값:  럽\n",
      "출력 값:  뢄 , 실제 값:  름\n",
      "출력 값:  뢄 , 실제 값:  름\n",
      "출력 값:  뢄 , 실제 값:  름\n",
      "출력 값:  뢄 , 실제 값:  름\n",
      "출력 값:  찐 , 실제 값:  참\n",
      "출력 값:  찐 , 실제 값:  참\n",
      "출력 값:  찐 , 실제 값:  참\n",
      "출력 값:  찐 , 실제 값:  참\n",
      "출력 값:  퐐 , 실제 값:  형\n",
      "출력 값:  퐔 , 실제 값:  형\n",
      "출력 값:  혐 , 실제 값:  형\n",
      "출력 값:  퐔 , 실제 값:  형\n",
      "출력 값:  화 , 실제 값:  확\n",
      "출력 값:  화 , 실제 값:  확\n",
      "출력 값:  화 , 실제 값:  확\n",
      "출력 값:  화 , 실제 값:  확\n",
      "출력 값:  룐 , 실제 값:  망\n",
      "출력 값:  룐 , 실제 값:  망\n",
      "출력 값:  룐 , 실제 값:  망\n",
      "출력 값:  룀 , 실제 값:  망\n",
      "출력 값:  쑼 , 실제 값:  야\n",
      "출력 값:  쑼 , 실제 값:  야\n",
      "출력 값:  쑼 , 실제 값:  야\n",
      "출력 값:  쑼 , 실제 값:  야\n",
      "출력 값:  좼 , 실제 값:  쪽\n",
      "출력 값:  슼 , 실제 값:  쪽\n",
      "출력 값:  좼 , 실제 값:  쪽\n",
      "출력 값:  쪼 , 실제 값:  쪽\n",
      "출력 값:  욄 , 실제 값:  임\n",
      "출력 값:  욄 , 실제 값:  임\n",
      "출력 값:  욄 , 실제 값:  임\n",
      "출력 값:  욄 , 실제 값:  임\n",
      "출력 값:  탄 , 실제 값:  포\n",
      "출력 값:  탄 , 실제 값:  포\n",
      "출력 값:  틄 , 실제 값:  포\n",
      "출력 값:  틄 , 실제 값:  포\n",
      "출력 값:  룰 , 실제 값:  민\n",
      "출력 값:  룰 , 실제 값:  민\n",
      "출력 값:  룰 , 실제 값:  민\n",
      "출력 값:  룰 , 실제 값:  민\n",
      "출력 값:  쓬 , 실제 값:  역\n",
      "출력 값:  쓬 , 실제 값:  역\n",
      "출력 값:  쓬 , 실제 값:  역\n",
      "출력 값:  쓤 , 실제 값:  역\n",
      "출력 값:  뢨 , 실제 값:  목\n",
      "출력 값:  뢨 , 실제 값:  목\n",
      "출력 값:  뢨 , 실제 값:  목\n",
      "출력 값:  뢨 , 실제 값:  목\n",
      "출력 값:  숐 , 실제 값:  순\n",
      "출력 값:  숐 , 실제 값:  순\n",
      "출력 값:  숐 , 실제 값:  순\n",
      "출력 값:  수 , 실제 값:  순\n",
      "출력 값:  변 , 실제 값:  별\n",
      "출력 값:  변 , 실제 값:  별\n",
      "출력 값:  변 , 실제 값:  별\n",
      "출력 값:  변 , 실제 값:  별\n",
      "출력 값:  술 , 실제 값:  술\n",
      "출력 값:  술 , 실제 값:  술\n",
      "출력 값:  술 , 실제 값:  술\n",
      "출력 값:  술 , 실제 값:  술\n",
      "출력 값:  갈 , 실제 값:  급\n",
      "출력 값:  갈 , 실제 값:  급\n",
      "출력 값:  갈 , 실제 값:  급\n",
      "출력 값:  갈 , 실제 값:  급\n",
      "출력 값:  올 , 실제 값:  올\n",
      "출력 값:  올 , 실제 값:  올\n",
      "출력 값:  올 , 실제 값:  올\n",
      "출력 값:  올 , 실제 값:  올\n",
      "출력 값:  끐 , 실제 값:  두\n",
      "출력 값:  끐 , 실제 값:  두\n",
      "출력 값:  두 , 실제 값:  두\n",
      "출력 값:  끐 , 실제 값:  두\n",
      "출력 값:  냀 , 실제 값:  평\n",
      "출력 값:  낀 , 실제 값:  평\n",
      "출력 값:  냀 , 실제 값:  평\n",
      "출력 값:  냀 , 실제 값:  평\n",
      "출력 값:  끀 , 실제 값:  년\n",
      "출력 값:  끀 , 실제 값:  년\n",
      "출력 값:  끄 , 실제 값:  년\n",
      "출력 값:  끀 , 실제 값:  년\n",
      "출력 값:  밀 , 실제 값:  번\n",
      "출력 값:  밀 , 실제 값:  번\n",
      "출력 값:  밀 , 실제 값:  번\n",
      "출력 값:  밀 , 실제 값:  번\n",
      "출력 값:  죀 , 실제 값:  질\n",
      "출력 값:  죀 , 실제 값:  질\n",
      "출력 값:  죀 , 실제 값:  질\n",
      "출력 값:  죀 , 실제 값:  질\n",
      "출력 값:  끰 , 실제 값:  데\n",
      "출력 값:  끰 , 실제 값:  데\n",
      "출력 값:  끰 , 실제 값:  데\n",
      "출력 값:  끰 , 실제 값:  데\n",
      "출력 값:  냄 , 실제 값:  담\n",
      "출력 값:  냔 , 실제 값:  담\n",
      "출력 값:  냄 , 실제 값:  담\n",
      "출력 값:  냄 , 실제 값:  담\n",
      "출력 값:  뀈 , 실제 값:  너\n",
      "출력 값:  뀈 , 실제 값:  너\n",
      "출력 값:  뀈 , 실제 값:  너\n",
      "출력 값:  뀈 , 실제 값:  너\n",
      "출력 값:  낀 , 실제 값:  늘\n",
      "출력 값:  낈 , 실제 값:  늘\n",
      "출력 값:  낀 , 실제 값:  늘\n",
      "출력 값:  낀 , 실제 값:  늘\n",
      "출력 값:  찐 , 실제 값:  천\n",
      "출력 값:  찐 , 실제 값:  천\n",
      "출력 값:  찐 , 실제 값:  천\n",
      "출력 값:  찐 , 실제 값:  천\n",
      "출력 값:  듔 , 실제 값:  드\n",
      "출력 값:  듔 , 실제 값:  드\n",
      "출력 값:  듔 , 실제 값:  드\n",
      "출력 값:  듔 , 실제 값:  드\n",
      "출력 값:  그 , 실제 값:  극\n",
      "출력 값:  그 , 실제 값:  극\n",
      "출력 값:  그 , 실제 값:  극\n",
      "출력 값:  그 , 실제 값:  극\n",
      "출력 값:  후 , 실제 값:  후\n",
      "출력 값:  후 , 실제 값:  후\n",
      "출력 값:  후 , 실제 값:  후\n",
      "출력 값:  후 , 실제 값:  후\n",
      "출력 값:  뀌 , 실제 값:  파\n",
      "출력 값:  뀌 , 실제 값:  파\n",
      "출력 값:  뀌 , 실제 값:  파\n",
      "출력 값:  뀀 , 실제 값:  파\n",
      "출력 값:  갨 , 실제 값:  격\n",
      "출력 값:  갨 , 실제 값:  격\n",
      "출력 값:  갨 , 실제 값:  격\n",
      "출력 값:  갨 , 실제 값:  격\n",
      "출력 값:  좜 , 실제 값:  증\n",
      "출력 값:  좜 , 실제 값:  증\n",
      "출력 값:  좜 , 실제 값:  증\n",
      "출력 값:  좌 , 실제 값:  증\n",
      "출력 값:  뀄 , 실제 값:  디\n",
      "출력 값:  뀄 , 실제 값:  디\n",
      "출력 값:  뀄 , 실제 값:  디\n",
      "출력 값:  뀄 , 실제 값:  디\n",
      "출력 값:  큀 , 실제 값:  필\n",
      "출력 값:  큀 , 실제 값:  필\n",
      "출력 값:  끀 , 실제 값:  필\n",
      "출력 값:  끀 , 실제 값:  필\n",
      "출력 값:  혰 , 실제 값:  혼\n",
      "출력 값:  혰 , 실제 값:  혼\n",
      "출력 값:  혴 , 실제 값:  혼\n",
      "출력 값:  혰 , 실제 값:  혼\n",
      "출력 값:  슴 , 실제 값:  습\n",
      "출력 값:  슴 , 실제 값:  습\n",
      "출력 값:  슴 , 실제 값:  습\n",
      "출력 값:  슴 , 실제 값:  습\n",
      "출력 값:  끈 , 실제 값:  노\n",
      "출력 값:  끈 , 실제 값:  노\n",
      "출력 값:  끘 , 실제 값:  노\n",
      "출력 값:  끈 , 실제 값:  노\n",
      "출력 값:  챜 , 실제 값:  최\n",
      "출력 값:  챜 , 실제 값:  최\n",
      "출력 값:  챜 , 실제 값:  최\n",
      "출력 값:  챜 , 실제 값:  최\n",
      "출력 값:  찐 , 실제 값:  창\n",
      "출력 값:  찐 , 실제 값:  창\n",
      "출력 값:  찐 , 실제 값:  창\n",
      "출력 값:  찐 , 실제 값:  창\n",
      "출력 값:  볰 , 실제 값:  본\n",
      "출력 값:  볰 , 실제 값:  본\n",
      "출력 값:  볰 , 실제 값:  본\n",
      "출력 값:  볰 , 실제 값:  본\n",
      "출력 값:  저 , 실제 값:  접\n",
      "출력 값:  저 , 실제 값:  접\n",
      "출력 값:  저 , 실제 값:  접\n",
      "출력 값:  저 , 실제 값:  접\n",
      "출력 값:  걨 , 실제 값:  깨\n",
      "출력 값:  걨 , 실제 값:  깨\n",
      "출력 값:  걨 , 실제 값:  깨\n",
      "출력 값:  걨 , 실제 값:  깨\n",
      "출력 값:  갰 , 실제 값:  길\n",
      "출력 값:  갸 , 실제 값:  길\n",
      "출력 값:  갰 , 실제 값:  길\n",
      "출력 값:  갸 , 실제 값:  길\n",
      "출력 값:  퐄 , 실제 값:  프\n",
      "출력 값:  퐄 , 실제 값:  프\n",
      "출력 값:  퐄 , 실제 값:  프\n",
      "출력 값:  퐄 , 실제 값:  프\n",
      "출력 값:  벀 , 실제 값:  법\n",
      "출력 값:  벀 , 실제 값:  법\n",
      "출력 값:  벀 , 실제 값:  법\n",
      "출력 값:  벀 , 실제 값:  법\n",
      "출력 값:  루 , 실제 값:  루\n",
      "출력 값:  루 , 실제 값:  루\n",
      "출력 값:  루 , 실제 값:  루\n",
      "출력 값:  루 , 실제 값:  루\n",
      "출력 값:  뀀 , 실제 값:  눈\n",
      "출력 값:  뀀 , 실제 값:  눈\n",
      "출력 값:  뀀 , 실제 값:  눈\n",
      "출력 값:  뀀 , 실제 값:  눈\n",
      "출력 값:  홐 , 실제 값:  환\n",
      "출력 값:  홐 , 실제 값:  환\n",
      "출력 값:  환 , 실제 값:  환\n",
      "출력 값:  홐 , 실제 값:  환\n",
      "출력 값:  였 , 실제 값:  은\n",
      "출력 값:  였 , 실제 값:  은\n",
      "출력 값:  였 , 실제 값:  은\n",
      "출력 값:  였 , 실제 값:  은\n",
      "출력 값:  쒀 , 실제 값:  잠\n",
      "출력 값:  쒀 , 실제 값:  잠\n",
      "출력 값:  쒀 , 실제 값:  잠\n",
      "출력 값:  쒀 , 실제 값:  잠\n",
      "출력 값:  쑜 , 실제 값:  앞\n",
      "출력 값:  쑜 , 실제 값:  앞\n",
      "출력 값:  쑜 , 실제 값:  앞\n",
      "출력 값:  쑜 , 실제 값:  앞\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  챔 , 실제 값:  코\n",
      "출력 값:  굔 , 실제 값:  코\n",
      "출력 값:  챔 , 실제 값:  코\n",
      "출력 값:  챔 , 실제 값:  코\n",
      "출력 값:  밀 , 실제 값:  밤\n",
      "출력 값:  밀 , 실제 값:  밤\n",
      "출력 값:  밀 , 실제 값:  밤\n",
      "출력 값:  밀 , 실제 값:  밤\n",
      "출력 값:  칀 , 실제 값:  침\n",
      "출력 값:  칀 , 실제 값:  침\n",
      "출력 값:  칀 , 실제 값:  침\n",
      "출력 값:  칀 , 실제 값:  침\n",
      "출력 값:  낀 , 실제 값:  난\n",
      "출력 값:  낀 , 실제 값:  난\n",
      "출력 값:  낈 , 실제 값:  난\n",
      "출력 값:  낀 , 실제 값:  난\n",
      "출력 값:  워 , 실제 값:  워\n",
      "출력 값:  워 , 실제 값:  워\n",
      "출력 값:  워 , 실제 값:  워\n",
      "출력 값:  워 , 실제 값:  워\n",
      "출력 값:  괸 , 실제 값:  꾸\n",
      "출력 값:  괸 , 실제 값:  꾸\n",
      "출력 값:  괸 , 실제 값:  꾸\n",
      "출력 값:  괸 , 실제 값:  꾸\n",
      "출력 값:  채 , 실제 값:  책\n",
      "출력 값:  채 , 실제 값:  책\n",
      "출력 값:  찄 , 실제 값:  책\n",
      "출력 값:  채 , 실제 값:  책\n",
      "출력 값:  쓴 , 실제 값:  열\n",
      "출력 값:  쓴 , 실제 값:  열\n",
      "출력 값:  쓴 , 실제 값:  열\n",
      "출력 값:  쓴 , 실제 값:  열\n",
      "출력 값:  닄 , 실제 값:  독\n",
      "출력 값:  닄 , 실제 값:  독\n",
      "출력 값:  닄 , 실제 값:  독\n",
      "출력 값:  닄 , 실제 값:  독\n",
      "출력 값:  찠 , 실제 값:  철\n",
      "출력 값:  찠 , 실제 값:  철\n",
      "출력 값:  찠 , 실제 값:  철\n",
      "출력 값:  찠 , 실제 값:  철\n",
      "출력 값:  산 , 실제 값:  쓰\n",
      "출력 값:  산 , 실제 값:  쓰\n",
      "출력 값:  산 , 실제 값:  쓰\n",
      "출력 값:  산 , 실제 값:  쓰\n",
      "출력 값:  군 , 실제 값:  군\n",
      "출력 값:  군 , 실제 값:  군\n",
      "출력 값:  군 , 실제 값:  군\n",
      "출력 값:  군 , 실제 값:  군\n",
      "출력 값:  둼 , 실제 값:  락\n",
      "출력 값:  둼 , 실제 값:  락\n",
      "출력 값:  둼 , 실제 값:  락\n",
      "출력 값:  둼 , 실제 값:  락\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 값:  쒀 , 실제 값:  잡\n",
      "출력 값:  쒀 , 실제 값:  잡\n",
      "출력 값:  쒀 , 실제 값:  잡\n",
      "출력 값:  쒀 , 실제 값:  잡\n",
      "출력 값:  벀 , 실제 값:  벌\n",
      "출력 값:  벀 , 실제 값:  벌\n",
      "출력 값:  벀 , 실제 값:  벌\n",
      "출력 값:  밀 , 실제 값:  벌\n",
      "출력 값:  욀 , 실제 값:  움\n",
      "출력 값:  욀 , 실제 값:  움\n",
      "출력 값:  욀 , 실제 값:  움\n",
      "출력 값:  움 , 실제 값:  움\n",
      "출력 값:  처 , 실제 값:  처\n",
      "출력 값:  처 , 실제 값:  처\n",
      "출력 값:  처 , 실제 값:  처\n",
      "출력 값:  첐 , 실제 값:  처\n",
      "출력 값:  푈 , 실제 값:  합\n",
      "출력 값:  푈 , 실제 값:  합\n",
      "출력 값:  푈 , 실제 값:  합\n",
      "출력 값:  푈 , 실제 값:  합\n",
      "출력 값:  쀨 , 실제 값:  씨\n",
      "출력 값:  쀨 , 실제 값:  씨\n",
      "출력 값:  쀨 , 실제 값:  씨\n",
      "출력 값:  쀨 , 실제 값:  씨\n",
      "출력 값:  킀 , 실제 값:  토\n",
      "출력 값:  킀 , 실제 값:  토\n",
      "출력 값:  킀 , 실제 값:  토\n",
      "출력 값:  킀 , 실제 값:  토\n",
      "출력 값:  풄 , 실제 값:  향\n",
      "출력 값:  풄 , 실제 값:  향\n",
      "출력 값:  풄 , 실제 값:  향\n",
      "출력 값:  풄 , 실제 값:  향\n",
      "출력 값:  삌 , 실제 값:  삼\n",
      "출력 값:  삌 , 실제 값:  삼\n",
      "출력 값:  삌 , 실제 값:  삼\n",
      "출력 값:  삌 , 실제 값:  삼\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  낀 , 실제 값:  능\n",
      "출력 값:  낀 , 실제 값:  능\n",
      "출력 값:  낀 , 실제 값:  능\n",
      "출력 값:  낀 , 실제 값:  능\n",
      "출력 값:  냄 , 실제 값:  답\n",
      "출력 값:  냄 , 실제 값:  답\n",
      "출력 값:  냄 , 실제 값:  답\n",
      "출력 값:  냄 , 실제 값:  답\n",
      "출력 값:  옠 , 실제 값:  육\n",
      "출력 값:  옠 , 실제 값:  육\n",
      "출력 값:  옠 , 실제 값:  육\n",
      "출력 값:  옠 , 실제 값:  육\n",
      "출력 값:  키 , 실제 값:  키\n",
      "출력 값:  키 , 실제 값:  키\n",
      "출력 값:  키 , 실제 값:  키\n",
      "출력 값:  키 , 실제 값:  키\n",
      "출력 값:  냈 , 실제 값:  님\n",
      "출력 값:  냈 , 실제 값:  님\n",
      "출력 값:  냈 , 실제 값:  님\n",
      "출력 값:  냈 , 실제 값:  님\n",
      "출력 값:  튰 , 실제 값:  특\n",
      "출력 값:  튰 , 실제 값:  특\n",
      "출력 값:  튰 , 실제 값:  특\n",
      "출력 값:  튰 , 실제 값:  특\n",
      "출력 값:  련 , 실제 값:  먹\n",
      "출력 값:  련 , 실제 값:  먹\n",
      "출력 값:  련 , 실제 값:  먹\n",
      "출력 값:  렸 , 실제 값:  먹\n",
      "출력 값:  갈 , 실제 값:  갈\n",
      "출력 값:  갈 , 실제 값:  갈\n",
      "출력 값:  갈 , 실제 값:  갈\n",
      "출력 값:  갈 , 실제 값:  갈\n",
      "출력 값:  삠 , 실제 값:  송\n",
      "출력 값:  삠 , 실제 값:  송\n",
      "출력 값:  삠 , 실제 값:  송\n",
      "출력 값:  삠 , 실제 값:  송\n",
      "출력 값:  쒐 , 실제 값:  잘\n",
      "출력 값:  쒘 , 실제 값:  잘\n",
      "출력 값:  쒐 , 실제 값:  잘\n",
      "출력 값:  쒘 , 실제 값:  잘\n",
      "출력 값:  끀 , 실제 값:  녀\n",
      "출력 값:  끀 , 실제 값:  녀\n",
      "출력 값:  끀 , 실제 값:  녀\n",
      "출력 값:  끀 , 실제 값:  녀\n",
      "출력 값:  퓘 , 실제 값:  험\n",
      "출력 값:  퓘 , 실제 값:  험\n",
      "출력 값:  퓘 , 실제 값:  험\n",
      "출력 값:  푘 , 실제 값:  험\n",
      "출력 값:  료 , 실제 값:  료\n",
      "출력 값:  료 , 실제 값:  료\n",
      "출력 값:  료 , 실제 값:  료\n",
      "출력 값:  료 , 실제 값:  료\n",
      "출력 값:  냘 , 실제 값:  태\n",
      "출력 값:  냜 , 실제 값:  태\n",
      "출력 값:  냜 , 실제 값:  태\n",
      "출력 값:  태 , 실제 값:  태\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for j, sample in enumerate(dataloader):\n",
    "        x = sample['image']\n",
    "        y = sample['label']\n",
    "        \n",
    "        output = loaded_model.forward(x)\n",
    "        for i in range(len(output)):\n",
    "            print(\"출력 값: \", decode_from_bin(output[i].tolist()),\n",
    "                  \", 실제 값: \", decode_from_bin(y[i].tolist()))\n",
    "            \n",
    "            #print(\"실제 값: \", output[i].tolist(),\n",
    "            #      \", 출력 값: \", y[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

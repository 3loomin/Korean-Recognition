{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run command 'conda install scikit-image' on project's v-env\n",
    "# run command 'conda install pandas' on project's v-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_TRAIN = False\n",
    "DEBUG_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_from_utf8(x):\n",
    "    return list(map(float,bin(int(x.encode().hex(),16))[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_from_bin(x):\n",
    "    res = \"\"\n",
    "    for i in x:\n",
    "        res+=str(round(i))\n",
    "        pass\n",
    "    return bytearray.fromhex(hex(int(res, 2))[2:]).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_from_bin2(x):\n",
    "    res = \"\"\n",
    "    for i in x:\n",
    "        res+=str(int(i>0))\n",
    "        pass\n",
    "    return bytearray.fromhex(hex(int(res, 2))[2:]).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class KoreanHandwritingDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.dataset = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.dataset.iloc[idx, 0]\n",
    "        image = io.imread(img_name)\n",
    "        label = self.dataset.iloc[idx, 1]\n",
    "        label = np.array([label])\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image/255.0\n",
    "        return {'image': torch.from_numpy(image.reshape(1,64,64)),\n",
    "                'label': torch.tensor(encode_from_utf8(label[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "csv_file = \"./image-data-256/labels-map.csv\"\n",
    "root_dir = \"./image-data-256/hangul-images\"\n",
    "batch_size=64\n",
    "learning_rate=0.0002\n",
    "num_epoch=100\n",
    "\n",
    "korean_dataset = KoreanHandwritingDataset(csv_file,root_dir, transform=transforms.Compose([ToTensor()]))\n",
    "dataloader = DataLoader(korean_dataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "#dataloader = DataLoader(korean_dataset, batch_size = batch_size, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.avgpool1 = nn.AvgPool2d(2,2) # kernel size 2x2 (32 = 64/2)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2,2) # kernel size 2x2 (32 = 64/2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(2,2) # kernel size 2x2 (16 = 32/2)\n",
    "        self.linear1 = nn.Linear(1152,378)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(378,128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(128,24)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        pass\n",
    "    def forward(self,x):\n",
    "        out = self.avgpool1(x)\n",
    "        if DEBUG_TRAIN : print('avgpool1: ', out.shape)\n",
    "        out = self.conv1(out)\n",
    "        if DEBUG_TRAIN : print('conv1: ', out.shape)\n",
    "        out = self.relu1(out)\n",
    "        if DEBUG_TRAIN : print('relu1: ', out.shape)\n",
    "        out = self.maxpool1(out)\n",
    "        if DEBUG_TRAIN : print('maxpool1: ', out.shape)\n",
    "        out = self.conv2(out)\n",
    "        if DEBUG_TRAIN : print('conv2: ', out.shape)\n",
    "        out = self.relu2(out)\n",
    "        if DEBUG_TRAIN : print('relu2: ', out.shape)\n",
    "        out = self.maxpool2(out)\n",
    "        if DEBUG_TRAIN : print('maxpool2: ', out.shape)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        if DEBUG_TRAIN : print('view: ', out.shape)\n",
    "        out = self.linear1(out)\n",
    "        if DEBUG_TRAIN : print('linear1: ', out.shape)\n",
    "        out = self.relu3(out)\n",
    "        if DEBUG_TRAIN : print('relu3: ', out.shape)\n",
    "        out = self.linear2(out)\n",
    "        if DEBUG_TRAIN : print('linear2: ', out.shape)\n",
    "        out = self.relu4(out)\n",
    "        if DEBUG_TRAIN : print('relu4: ', out.shape)\n",
    "        out = self.linear3(out)\n",
    "        if DEBUG_TRAIN : print('linear3: ', out.shape)\n",
    "        #out = self.sigmoid(out)\n",
    "        #if DEBUG_TRAIN : print('sigmoid: ', out.shape)\n",
    "        if DEBUG_TRAIN : print()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model=CNN().double()\n",
    "loss_function=nn.BCEWithLogitsLoss()\n",
    "#loss_function=nn.\n",
    "optimizer= torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 sequence:  0 tensor(0.6976, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  2 sequence:  0 tensor(0.6086, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  3 sequence:  0 tensor(0.4308, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  4 sequence:  0 tensor(0.4061, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  5 sequence:  0 tensor(0.3934, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  6 sequence:  0 tensor(0.3989, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  7 sequence:  0 tensor(0.3946, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  8 sequence:  0 tensor(0.3994, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  9 sequence:  0 tensor(0.3945, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  10 sequence:  0 tensor(0.3943, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  11 sequence:  0 tensor(0.3922, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  12 sequence:  0 tensor(0.3940, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  13 sequence:  0 tensor(0.3876, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  14 sequence:  0 tensor(0.3891, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  15 sequence:  0 tensor(0.3905, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  16 sequence:  0 tensor(0.3810, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  17 sequence:  0 tensor(0.3860, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  18 sequence:  0 tensor(0.3733, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  19 sequence:  0 tensor(0.3740, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  20 sequence:  0 tensor(0.3701, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  21 sequence:  0 tensor(0.3705, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  22 sequence:  0 tensor(0.3587, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  23 sequence:  0 tensor(0.3572, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  24 sequence:  0 tensor(0.3570, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  25 sequence:  0 tensor(0.3506, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  26 sequence:  0 tensor(0.3564, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  27 sequence:  0 tensor(0.3476, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  28 sequence:  0 tensor(0.3433, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  29 sequence:  0 tensor(0.3389, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  30 sequence:  0 tensor(0.3450, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  31 sequence:  0 tensor(0.3330, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  32 sequence:  0 tensor(0.3526, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  33 sequence:  0 tensor(0.3135, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  34 sequence:  0 tensor(0.3253, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  35 sequence:  0 tensor(0.3196, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  36 sequence:  0 tensor(0.3097, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  37 sequence:  0 tensor(0.3113, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  38 sequence:  0 tensor(0.3055, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  39 sequence:  0 tensor(0.3046, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  40 sequence:  0 tensor(0.3189, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  41 sequence:  0 tensor(0.2943, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  42 sequence:  0 tensor(0.3031, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  43 sequence:  0 tensor(0.2999, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  44 sequence:  0 tensor(0.2851, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  45 sequence:  0 tensor(0.2904, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  46 sequence:  0 tensor(0.3033, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  47 sequence:  0 tensor(0.3057, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  48 sequence:  0 tensor(0.3099, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  49 sequence:  0 tensor(0.2873, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  50 sequence:  0 tensor(0.3013, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  51 sequence:  0 tensor(0.2801, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  52 sequence:  0 tensor(0.2745, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  53 sequence:  0 tensor(0.2786, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  54 sequence:  0 tensor(0.2567, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  55 sequence:  0 tensor(0.2495, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  56 sequence:  0 tensor(0.2592, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  57 sequence:  0 tensor(0.2675, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  58 sequence:  0 tensor(0.2705, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  59 sequence:  0 tensor(0.2573, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  60 sequence:  0 tensor(0.2725, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  61 sequence:  0 tensor(0.2642, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  62 sequence:  0 tensor(0.2424, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  63 sequence:  0 tensor(0.2485, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  64 sequence:  0 tensor(0.2562, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  65 sequence:  0 tensor(0.2589, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  66 sequence:  0 tensor(0.2387, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  67 sequence:  0 tensor(0.2550, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  68 sequence:  0 tensor(0.2524, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  69 sequence:  0 tensor(0.2393, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  70 sequence:  0 tensor(0.2407, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  71 sequence:  0 tensor(0.2471, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  72 sequence:  0 tensor(0.2481, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  73 sequence:  0 tensor(0.2362, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  74 sequence:  0 tensor(0.2469, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  75 sequence:  0 tensor(0.2310, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  76 sequence:  0 tensor(0.2355, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  77 sequence:  0 tensor(0.2170, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  78 sequence:  0 tensor(0.2496, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  79 sequence:  0 tensor(0.2236, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  80 sequence:  0 tensor(0.2561, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  81 sequence:  0 tensor(0.2339, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  82 sequence:  0 tensor(0.2286, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  83 sequence:  0 tensor(0.2345, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  84 sequence:  0 tensor(0.2355, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  85 sequence:  0 tensor(0.2295, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  86 sequence:  0 tensor(0.2253, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  87 sequence:  0 tensor(0.2217, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  88 sequence:  0 tensor(0.2311, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  89 sequence:  0 tensor(0.2328, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  90 sequence:  0 tensor(0.2247, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  91 sequence:  0 tensor(0.2077, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  92 sequence:  0 tensor(0.2104, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  93 sequence:  0 tensor(0.2066, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  94 sequence:  0 tensor(0.2123, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  95 sequence:  0 tensor(0.2094, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  96 sequence:  0 tensor(0.2164, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  97 sequence:  0 tensor(0.2094, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  98 sequence:  0 tensor(0.2139, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  99 sequence:  0 tensor(0.1888, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "epoch:  100 sequence:  0 tensor(0.2116, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_arr=[]\n",
    "for i in range(num_epoch):\n",
    "    for j, sample in enumerate(dataloader):\n",
    "        x = sample['image']\n",
    "        y = sample['label']\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(x)\n",
    "        loss=loss_function(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j == 0:\n",
    "            if DEBUG_DATA:\n",
    "                plt.figure(figsize=(32, 32))\n",
    "                for k, img in enumerate(x):\n",
    "                    plt.subplot(8, 8, k+1)\n",
    "                    plt.imshow(img.squeeze())\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "                    pass\n",
    "                plt.show()\n",
    "            print('epoch: ', i+1, 'sequence: ', j, loss)\n",
    "            loss_arr.append(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 값:  샰 , 실제 값:  쓰\n",
      "출력 값:  닼 , 실제 값:  답\n",
      "출력 값:  밀 , 실제 값:  버\n",
      "출력 값:  뷨 , 실제 값:  불\n",
      "출력 값:  혼 , 실제 값:  혼\n",
      "출력 값:  쒨 , 실제 값:  체\n",
      "출력 값:  뻌 , 실제 값:  들\n",
      "출력 값:  샬 , 실제 값:  실\n",
      "출력 값:  니 , 실제 값:  노\n",
      "출력 값:  린 , 실제 값:  분\n",
      "출력 값:  일 , 실제 값:  어\n",
      "출력 값:  쟌 , 실제 값:  임\n",
      "출력 값:  첨 , 실제 값:  물\n",
      "출력 값:  샬 , 실제 값:  시\n",
      "출력 값:  쇍 , 실제 값:  석\n",
      "출력 값:  야 , 실제 값:  앞\n",
      "출력 값:  틭 , 실제 값:  력\n",
      "출력 값:  낀 , 실제 값:  늘\n",
      "출력 값:  팰 , 실제 값:  편\n",
      "출력 값:  삅 , 실제 값:  속\n",
      "출력 값:  휨 , 실제 값:  판\n",
      "출력 값:  원 , 실제 값:  월\n",
      "출력 값:  띤 , 실제 값:  매\n",
      "출력 값:  일 , 실제 값:  외\n",
      "출력 값:  뷬 , 실제 값:  만\n",
      "출력 값:  좀 , 실제 값:  절\n",
      "출력 값:  뢩 , 실제 값:  복\n",
      "출력 값:  엽 , 실제 값:  약\n",
      "출력 값:  쎱 , 실제 값:  송\n",
      "출력 값:  룼 , 실제 값:  르\n",
      "출력 값:  낈 , 실제 값:  너\n",
      "출력 값:  츘 , 실제 값:  처\n",
      "출력 값:  읜 , 실제 값:  외\n",
      "출력 값:  댬 , 실제 값:  려\n",
      "출력 값:  당 , 실제 값:  당\n",
      "출력 값:  잠 , 실제 값:  잘\n",
      "출력 값:  홌 , 실제 값:  표\n",
      "출력 값:  놔 , 실제 값:  망\n",
      "출력 값:  신 , 실제 값:  신\n",
      "출력 값:  삐 , 실제 값:  손\n",
      "출력 값:  샽 , 실제 값:  성\n",
      "출력 값:  심 , 실제 값:  십\n",
      "출력 값:  솬 , 실제 값:  소\n",
      "출력 값:  룼 , 실제 값:  본\n",
      "출력 값:  쮀 , 실제 값:  진\n",
      "출력 값:  늀 , 실제 값:  눈\n",
      "출력 값:  읠 , 실제 값:  은\n",
      "출력 값:  버 , 실제 값:  별\n",
      "출력 값:  쎬 , 실제 값:  소\n",
      "출력 값:  처 , 실제 값:  처\n",
      "출력 값:  엤 , 실제 값:  열\n",
      "출력 값:  늩 , 실제 값:  능\n",
      "출력 값:  펰 , 실제 값:  통\n",
      "출력 값:  펁 , 실제 값:  평\n",
      "출력 값:  덴 , 실제 값:  매\n",
      "출력 값:  흜 , 실제 값:  험\n",
      "출력 값:  갑 , 실제 값:  강\n",
      "출력 값:  욨 , 실제 값:  울\n",
      "출력 값:  입 , 실제 값:  영\n",
      "출력 값:  심 , 실제 값:  심\n",
      "출력 값:  욡 , 실제 값:  육\n",
      "출력 값:  탰 , 실제 값:  토\n",
      "출력 값:  늀 , 실제 값:  눈\n",
      "출력 값:  쟅 , 실제 값:  입\n",
      "출력 값:  쳘 , 실제 값:  철\n",
      "출력 값:  휜 , 실제 값:  피\n",
      "출력 값:  샼 , 실제 값:  세\n",
      "출력 값:  뙠 , 실제 값:  매\n",
      "출력 값:  뒔 , 실제 값:  배\n",
      "출력 값:  옘 , 실제 값:  차\n",
      "출력 값:  띨 , 실제 값:  깨\n",
      "출력 값:  낈 , 실제 값:  나\n",
      "출력 값:  트 , 실제 값:  특\n",
      "출력 값:  야 , 실제 값:  야\n",
      "출력 값:  단 , 실제 값:  들\n",
      "출력 값:  즍 , 실제 값:  종\n",
      "출력 값:  삼 , 실제 값:  서\n",
      "출력 값:  쟄 , 실제 값:  영\n",
      "출력 값:  핝 , 실제 값:  향\n",
      "출력 값:  냸 , 실제 값:  단\n",
      "출력 값:  튨 , 실제 값:  토\n",
      "출력 값:  활 , 실제 값:  프\n",
      "출력 값:  쟭 , 실제 값:  역\n",
      "출력 값:  좜 , 실제 값:  계\n",
      "출력 값:  뇸 , 실제 값:  대\n",
      "출력 값:  슜 , 실제 값:  수\n",
      "출력 값:  짠 , 실제 값:  조\n",
      "출력 값:  유 , 실제 값:  잠\n",
      "출력 값:  굸 , 실제 값:  근\n",
      "출력 값:  변 , 실제 값:  변\n",
      "출력 값:  쐜 , 실제 값:  천\n",
      "출력 값:  닼 , 실제 값:  담\n",
      "출력 값:  닸 , 실제 값:  담\n",
      "출력 값:  표 , 실제 값:  한\n",
      "출력 값:  찙 , 실제 값:  창\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-75164208668b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             print(\"출력 값: \", decode_from_bin2(output[i].tolist()),\n\u001b[0m\u001b[1;32m      9\u001b[0m                   \", 실제 값: \", decode_from_bin(y[i].tolist()))\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m#print(\"실제 값: \", output[i].tolist(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-90164c9ef365>\u001b[0m in \u001b[0;36mdecode_from_bin2\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for j, sample in enumerate(dataloader):\n",
    "        x = sample['image']\n",
    "        y = sample['label']\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        for i in range(len(output)):\n",
    "            print(\"출력 값: \", decode_from_bin2(output[i].tolist()),\n",
    "                  \", 실제 값: \", decode_from_bin(y[i].tolist()))\n",
    "            #print(\"실제 값: \", output[i].tolist(),\n",
    "            #      \", 출력 값: \", y[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
